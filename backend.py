import json
import os
import chromadb
from chromadb.utils import embedding_functions
from openai import OpenAI
import shutil # <--- æ–°å¢
import glob   # <--- æ–°å¢
from datetime import datetime # <--- å¿…é¡»åŠ è¿™ä¸€è¡Œï¼

import networkx as nx

import hashlib

class WorldGraph:
    def __init__(self, manager):
        self.manager = manager
        self.G = nx.DiGraph() # æœ‰å‘å›¾

    # ã€æ ¸å¿ƒã€‘ä»ç°æœ‰çš„ app_state åŠ¨æ€æ„å»ºå›¾è°±
    # æ¯æ¬¡å†™ä½œå‰è°ƒç”¨ä¸€æ¬¡ï¼Œä¿è¯æ•°æ®æœ€æ–°
    def rebuild(self):
        self.G.clear()
        
        # 1. åŠ è½½äººç‰©æ•°æ® (ç°æœ‰æ ¼å¼)
        # char: {'name': 'å¶å‡¡', 'relations': [{'target': 'é»‘çš‡', 'type': 'æŸå‹'}]}
        chars = self.manager.load_characters()
        for c in chars:
            # æ·»åŠ äººç‰©èŠ‚ç‚¹
            self.G.add_node(c['name'], type='character', desc=c.get('bio', '')[:50])
            
            # æ·»åŠ äººç‰©å…³ç³»è¾¹
            for rel in c.get('relations', []):
                # ç¡®ä¿ç›®æ ‡èŠ‚ç‚¹ä¹Ÿå­˜åœ¨ï¼ˆé˜²æ­¢æ­»é“¾ï¼‰
                if rel['target']:
                    self.G.add_edge(c['name'], rel['target'], relation=rel['type'], weight=2)

        # 2. åŠ è½½åœ°ç‚¹æ•°æ® (ç°æœ‰æ ¼å¼)
        # loc: {'name': 'ç´«å±±', 'neighbors': ['çŸ¿åŒº'], 'parent': 'åŒ—åŸŸ'}
        locs = self.manager.load_locations()
        for l in locs:
            # æ·»åŠ åœ°ç‚¹èŠ‚ç‚¹
            self.G.add_node(l['name'], type='location', desc=l.get('desc', '')[:50])
            
            # æ·»åŠ æ‹“æ‰‘è¿æ¥ (åŒå‘è¾¹)
            for n in l.get('neighbors', []):
                self.G.add_edge(l['name'], n, relation="è¿é€š", weight=1)
            
            # æ·»åŠ è¡Œæ”¿å½’å± (çˆ¶å­è¾¹)
            if l.get('parent'):
                self.G.add_edge(l['name'], l['parent'], relation="å±äº", weight=0.5)

        # 3. åŠ è½½ç‰©å“æ•°æ® (ç°æœ‰æ ¼å¼) -> å…³è”åˆ°æŒæœ‰è€…
        # item: {'name': 'ä¸‡ç‰©æ¯æ°”é¼', 'owner': 'å¶å‡¡'}
        items = self.manager.load_items()
        for i in items:
            self.G.add_node(i['name'], type='item', desc=i.get('desc', '')[:50])
            if i.get('owner'):
                self.G.add_edge(i['owner'], i['name'], relation="æŒæœ‰", weight=3)

    # --- GraphRAG åŠŸèƒ½ï¼šè·å–æŸäººçš„â€œå…³ç³»ç½‘æ–‡æœ¬â€ ---
    def get_context_text(self, center_node, hops=1):
        if center_node not in self.G: return ""
        
        # æå– 1-2 è·³çš„å­å›¾
        # æ¯”å¦‚ï¼šå¶å‡¡ ->(æŒæœ‰)-> é¼ï¼› å¶å‡¡ ->(ä»‡äºº)-> å§¬çš“æœˆ
        nodes = {center_node}
        for _ in range(hops):
            new_nodes = set()
            for n in nodes:
                new_nodes.update(self.G.neighbors(n))      # æˆ‘è¿åˆ«äºº
                new_nodes.update(self.G.predecessors(n))   # åˆ«äººè¿æˆ‘
            nodes.update(new_nodes)
        
        subgraph = self.G.subgraph(nodes)
        
        # è½¬æˆè‡ªç„¶è¯­è¨€æ–‡æœ¬ï¼Œå–‚ç»™ AI
        lines = []
        for u, v, d in subgraph.edges(data=True):
            rel = d.get('relation', 'å…³è”')
            lines.append(f"- {u} {rel} {v}")
            
        return "\n".join(lines)

    # --- å¯»è·¯åŠŸèƒ½ï¼šæŸ¥æ‰¾ä¸¤è€…å…³ç³» ---
    def find_relation_path(self, start, end):
        try:
            path = nx.shortest_path(self.G, start, end)
            return " -> ".join(path)
        except:
            return ""
    # ã€æ–°å¢ã€‘å¯¼å‡º ECharts å¯è§†åŒ–æ•°æ®
    def get_echarts_data(self):
        nodes = []
        links = []
        categories = [{"name": "character"}, {"name": "location"}, {"name": "item"}]
        
        # é¢œè‰²é…ç½® (Hardcoded for stability)
        color_map = {
            "character": "#5470c6", # è“
            "location": "#91cc75",  # ç»¿
            "item": "#fac858"       # é»„
        }

        for n, attr in self.G.nodes(data=True):
            ntype = attr.get('type', 'unknown')
            # æ ¹æ®ç±»å‹å†³å®šå¤§å°
            symbol_size = 30
            if ntype == 'location': symbol_size = 40
            elif ntype == 'item': symbol_size = 20
            
            nodes.append({
                "name": n,
                "category": ntype, # å¯¹åº” categories ä¸‹æ ‡æˆ–åç§°
                "symbolSize": symbol_size,
                "draggable": True,
                "value": attr.get('desc', '')[:20],
                "itemStyle": {"color": color_map.get(ntype, '#ccc')},
                "label": {"show": True, "position": "right"}
            })
        
        for u, v, attr in self.G.edges(data=True):
            links.append({
                "source": u,
                "target": v,
                "value": attr.get('relation', ''),
                "label": {"show": True, "formatter": "{c}"}, # æ˜¾ç¤ºå…³ç³»å
                "lineStyle": {"curveness": 0.2, "color": "source"}
            })
            
        return {"nodes": nodes, "links": links, "categories": categories}

# ================= é…ç½®åŠ è½½ =================
def load_config():
    # ä¼˜å…ˆè¯»å– config.jsonï¼Œä¸å­˜åœ¨åˆ™è¯»å– config.example.jsonï¼Œå†æ²¡æœ‰åˆ™è¿”å›ç©º
    if os.path.exists("config.json"):
        with open("config.json", 'r', encoding='utf-8') as f:
            return json.load(f)
    elif os.path.exists("config.example.json"):
        with open("config.example.json", 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}

CFG = load_config()
# åˆå§‹åŒ–å…¨å±€ client
client = OpenAI(api_key=CFG.get('api_key'), base_url=CFG.get('base_url'))

# ã€æ–°å¢ã€‘ä¿å­˜é…ç½®å¹¶çƒ­é‡è½½
def save_global_config(new_config):
    global CFG, client
    try:
        # 1. å†™å…¥æ–‡ä»¶
        with open("config.json", 'w', encoding='utf-8') as f:
            json.dump(new_config, f, ensure_ascii=False, indent=4)
        
        # 2. çƒ­æ›´æ–°å†…å­˜ä¸­çš„é…ç½®
        CFG.update(new_config)
        
        # 3. é‡ç½® OpenAI å®¢æˆ·ç«¯ (è¿™ä¸€æ­¥å¾ˆå…³é”®ï¼Œå¦åˆ™æ”¹äº† Key ä¸ç”Ÿæ•ˆ)
        client = OpenAI(api_key=CFG.get('api_key'), base_url=CFG.get('base_url'))
        
        return "âœ… é…ç½®å·²ä¿å­˜ï¼Œç³»ç»Ÿå·²çƒ­é‡è½½"
    except Exception as e:
        return f"âŒ ä¿å­˜å¤±è´¥: {str(e)}"

# 1. æ–°å¢ï¼šä¹¦æ¶ç®¡ç†å™¨
class LibraryManager:
    def __init__(self):
        # æ‰€æœ‰å°è¯´é»˜è®¤å­˜æ”¾åœ¨ 'projects' æ–‡ä»¶å¤¹ä¸‹
        self.base_dir = CFG.get('project_base_dir', 'projects') # å»ºè®®è¯»é…ç½®ï¼Œæ— é…ç½®åˆ™é»˜è®¤ä¸º 'projects'
        if not os.path.exists(self.base_dir): os.makedirs(self.base_dir)

    def list_books(self):
        """åˆ—å‡ºæ‰€æœ‰é¡¹ç›®"""
        books = []
        if not os.path.exists(self.base_dir): return []
        
        for name in os.listdir(self.base_dir):
            path = os.path.join(self.base_dir, name)
            if os.path.isdir(path):
                # ç®€å•åˆ—å‡ºæ–‡ä»¶å¤¹åä½œä¸ºä¹¦å
                books.append({"name": name})
        return books

    def create_book(self, book_name):
        """åˆ›å»ºæ–°ä¹¦ç»“æ„"""
        # 1. å‡€åŒ–æ–‡ä»¶å (é˜²æ­¢éæ³•å­—ç¬¦)
        safe_name = "".join([c for c in book_name if c.isalpha() or c.isdigit() or c in (' ', '_', '-')]).strip()
        if not safe_name: safe_name = f"Book_{datetime.now().strftime('%Y%m%d')}"
        
        path = os.path.join(self.base_dir, safe_name)
        
        # 2. æ£€æŸ¥æ˜¯å¦å­˜åœ¨
        if os.path.exists(path): return False, "åŒåä¹¦ç±å·²å­˜åœ¨"
        
        try:
            # 3. åˆ›å»ºç›®å½•
            os.makedirs(path)
            
            # 4. åˆå§‹åŒ–è¯¥ä¹¦çš„åŸºç¡€æ–‡ä»¶
            # è¿™é‡Œæˆ‘ä»¬ä¸´æ—¶å®ä¾‹åŒ–ä¸€ä¸ª NovelManager æ¥å¸®æˆ‘ä»¬ç”Ÿæˆæ–‡ä»¶ç»“æ„
            # æ³¨æ„ï¼šè¿™é‡Œä¼ å…¥ project_root è®© Manager çŸ¥é“å»å“ªé‡Œåˆå§‹åŒ–
            temp_mgr = NovelManager(project_root=path)
            
            return True, safe_name
        except Exception as e:
            return False, str(e)

    # --- æ–°å¢ï¼šé‡å‘½åä¹¦ç± ---
    def rename_book(self, old_name, new_name):
        """é‡å‘½åä¹¦ç±æ–‡ä»¶å¤¹"""
        # 1. æ£€æŸ¥åŸä¹¦æ˜¯å¦å­˜åœ¨
        old_path = os.path.join(self.base_dir, old_name)
        if not os.path.exists(old_path):
            return False, "åŸä¹¦ç±ä¸å­˜åœ¨"

        # 2. å‡€åŒ–æ–°ä¹¦å (é˜²æ­¢éæ³•å­—ç¬¦)
        safe_new_name = "".join([c for c in new_name if c.isalpha() or c.isdigit() or c in (' ', '_', '-')]).strip()
        if not safe_new_name: 
            return False, "æ–°ä¹¦åæ— æ•ˆ"
        
        new_path = os.path.join(self.base_dir, safe_new_name)

        # 3. æ£€æŸ¥æ–°åæ˜¯å¦å†²çª
        if os.path.exists(new_path):
            return False, "è¯¥ä¹¦åå·²å­˜åœ¨"

        try:
            # 4. æ‰§è¡Œé‡å‘½å
            os.rename(old_path, new_path)
            
            # ã€é‡è¦ã€‘å¦‚æœè¿™æ­£æ˜¯å½“å‰æ‰“å¼€çš„ä¹¦ï¼Œä¹Ÿéœ€è¦æ›´æ–°å…¨å±€é…ç½®é‡Œçš„è®°å½•
            # è¿™éƒ¨åˆ†é€»è¾‘é€šå¸¸åœ¨ UI å±‚å¤„ç†çŠ¶æ€ï¼Œä½†åœ¨è¿™é‡Œæˆ‘ä»¬åªè´Ÿè´£æ–‡ä»¶ç³»ç»Ÿ
            
            return True, safe_new_name
        except Exception as e:
            return False, str(e)
    # --- æ–°å¢ï¼šåˆ é™¤ä¹¦ç± ---
    def delete_book(self, book_name):
        print(f"[Backend] æ­£åœ¨å°è¯•åˆ é™¤ä¹¦ç±: {book_name}") # <--- è°ƒè¯•æ—¥å¿—
        
        # 1. è·¯å¾„æ£€æŸ¥
        book_path = os.path.join(self.base_dir, book_name)
        if not os.path.exists(book_path):
            return False, "ä¹¦ç±ç›®å½•ä¸å­˜åœ¨"

        try:
            # 2. åˆ é™¤ç‰©ç†æ–‡ä»¶å¤¹
            import shutil # å†æ¬¡ç¡®ä¿å¯¼å…¥
            shutil.rmtree(book_path)
            
            # 3. åˆ é™¤å‘é‡æ•°æ®åº“
            try:
                import hashlib
                hash_object = hashlib.md5(book_name.encode('utf-8'))
                hex_dig = hash_object.hexdigest()
                collection_name = f"novel_{hex_dig}"
                
                db_path = "chroma_db_storage"
                if os.path.exists(db_path):
                    # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦æ–°å»ºä¸€ä¸ª client è¿æ¥æ¥æ‰§è¡Œåˆ é™¤
                    client = chromadb.PersistentClient(path=db_path)
                    client.delete_collection(collection_name)
                    print(f"[Backend] å‘é‡åº“ {collection_name} å·²åˆ é™¤")
            except Exception as e:
                print(f"[Backend] å‘é‡åº“æ¸…ç†è­¦å‘Š: {e}") # ä¹Ÿå°±æ˜¯å…è®¸å‘é‡åº“åˆ é™¤å¤±è´¥ï¼Œä¸å½±å“ä¸»æµç¨‹

            return True, f"ã€Š{book_name}ã€‹å·²æ°¸ä¹…åˆ é™¤"

        except Exception as e:
            import traceback
            traceback.print_exc() # æ‰“å°è¯¦ç»†æŠ¥é”™
            return False, f"åˆ é™¤å¤±è´¥: {str(e)}"
# ================= å°è¯´ç®¡ç†å™¨ (æ•°æ®å±‚) =================
class NovelManager:
    def __init__(self, project_root=None):
        # å¦‚æœä¼ å…¥äº†è·¯å¾„ï¼Œå°±ç”¨ä¼ å…¥çš„ï¼›å¦åˆ™è¯»é…ç½®ï¼›æœ€åå›é€€åˆ°é»˜è®¤
        if project_root:
            self.root_dir = project_root
        else:
            self.root_dir = CFG.get('project_dir', 'projects/Default_Book')
            
        self.chapters_dir = os.path.join(self.root_dir, "chapters")
        self.setting_file = os.path.join(self.root_dir, "setting.json")
        self.char_file = os.path.join(self.root_dir, "characters.json")
        self.item_file = os.path.join(self.root_dir, "items.json")
        self.loc_file = os.path.join(self.root_dir, "locations.json")
        self.structure_file = os.path.join(self.root_dir, "structure.json")
        self.volume_file = os.path.join(self.root_dir, "volumes.json")
        self._init_fs()

    def _init_fs(self):
        if not os.path.exists(self.chapters_dir): os.makedirs(self.chapters_dir)
        
        if not os.path.exists(self.setting_file):
            with open(self.setting_file, 'w', encoding='utf-8') as f:
                json.dump({"world_view": "", "characters": "", "book_summary": ""}, f, ensure_ascii=False, indent=4)
        
        if not os.path.exists(self.char_file):
            default_chars = [{
                "name": "ä¸»è§’", "gender": "ç”·", "role": "ä¸»è§’", 
                "status": "å­˜æ´»", "bio": "æ€§æ ¼åšæ¯…ã€‚", "relations": []
            }]
            with open(self.char_file, 'w', encoding='utf-8') as f:
                json.dump(default_chars, f, ensure_ascii=False, indent=4)

        if not os.path.exists(self.item_file):
            with open(self.item_file, 'w', encoding='utf-8') as f: json.dump([], f)
        
        if not os.path.exists(self.loc_file):
            with open(self.loc_file, 'w', encoding='utf-8') as f: json.dump([], f)

        if not os.path.exists(self.volume_file):
            default_vol = [{"id": "vol_default", "title": "æ­£æ–‡å·", "order": 1}]
            with open(self.volume_file, 'w', encoding='utf-8') as f:
                json.dump(default_vol, f, ensure_ascii=False, indent=4)

        if not os.path.exists(self.structure_file):
            default_structure = [{
                "id": 1, 
                "title": "ç¬¬ä¸€ç« ", 
                "volume_id": "vol_default", 
                "outline": "å¼€å±€ã€‚", 
                "summary": "", 
                "time_info": {"label": "æ•…äº‹å¼€å§‹", "duration": "0", "events": []}
            }]
            with open(self.structure_file, 'w', encoding='utf-8') as f:
                json.dump(default_structure, f, ensure_ascii=False, indent=4)

    # --- åŸºç¡€è¯»å†™ ---
    def load_settings(self):
        try:
            with open(self.setting_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return {}

    def save_settings(self, data):
        with open(self.setting_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
    
    def load_characters(self):
        try:
            with open(self.char_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                for char in data:
                    if 'relations' not in char: char['relations'] = []
                return data
        except: return []

    def save_characters(self, data):
        with open(self.char_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)

    def load_items(self):
        try:
            with open(self.item_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return []

    def save_items(self, data):
        with open(self.item_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)

    def load_locations(self):
        try:
            with open(self.loc_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return []

    def save_locations(self, data):
        with open(self.loc_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)

    def load_volumes(self):
        try:
            with open(self.volume_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return []

    def save_volumes(self, data):
        with open(self.volume_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)

    def load_structure(self):
        try:
            with open(self.structure_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                for chap in data:
                    if 'time_info' not in chap:
                        chap['time_info'] = {"label": "æœªçŸ¥æ—¶é—´", "duration": "-", "events": []}
                    if 'volume_id' not in chap:
                        chap['volume_id'] = "vol_default"
                return data
        except: return []

    def save_structure(self, data):
        with open(self.structure_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
    
    def save_chapter_content(self, chapter_id, content):
        with open(os.path.join(self.chapters_dir, f"{chapter_id}.txt"), 'w', encoding='utf-8') as f:
            f.write(content)
    
    def load_chapter_content(self, chapter_id):
        path = os.path.join(self.chapters_dir, f"{chapter_id}.txt")
        return open(path, 'r', encoding='utf-8').read() if os.path.exists(path) else ""
    
    def delete_chapter(self, chapter_id):
        path = os.path.join(self.chapters_dir, f"{chapter_id}.txt")
        if os.path.exists(path): os.remove(path)

    def get_total_word_count(self):
        structure = self.load_structure()
        total = 0
        for chap in structure:
            content = self.load_chapter_content(chap['id'])
            total += len(content)
        return total

    def get_relevant_context(self, text_context):
        chars = self.load_characters()
        items = self.load_items()
        locs = self.load_locations()
        
        active_info = []
        active_names = []

        found_chars = [c for c in chars if c['name'] in text_context]
        if not found_chars and chars: found_chars.append(chars[0])
        
        if found_chars:
            active_info.append("ã€ç›¸å…³äººç‰©ã€‘")
            for c in found_chars:
                rels = ", ".join([f"{r['type']}->{r['target']}" for r in c.get('relations', [])])
                rel_str = f" [å…³ç³»: {rels}]" if rels else ""
                active_info.append(f"- {c['name']} ({c['gender']}/{c['role']}/{c['status']}){rel_str}: {c['bio']}")
                active_names.append(c['name'])

        found_items = [i for i in items if i['name'] in text_context]
        if found_items:
            active_info.append("ã€ç›¸å…³ç‰©å“ã€‘")
            for i in found_items:
                active_info.append(f"- {i['name']} ({i['type']}/æŒæœ‰:{i['owner']}): {i['desc']}")
                active_names.append(i['name'])

        found_locs = [l for l in locs if l['name'] in text_context]
        if found_locs:
            active_info.append("ã€ç›¸å…³åœ°ç‚¹ã€‘")
            for l in found_locs:
                active_info.append(f"- {l['name']} ({l['faction']}): {l['desc']}")
                active_names.append(l['name'])

        return "\n".join(active_info), active_names

    def smart_rag_pipeline(self, query, current_chapter_id, memory_manager):
        print(f"\n[Smart RAG] å¯åŠ¨æ™ºèƒ½æ£€ç´¢: {query[:20]}...")
        raw_docs, debug_info = memory_manager.query_related_memory(
            query, n_results=8, threshold=1.6, exclude_chapter_id=current_chapter_id
        )
        if not raw_docs: return "ï¼ˆæ— ç›¸å…³å†å²è®°å¿†ï¼‰", []

        processed_snippets = []
        for item in debug_info:
            source_id = int(item['source'].replace("ç¬¬", "").replace("ç« ", ""))
            distance = current_chapter_id - source_id
            prefix = "[REF]"
            if 1 <= distance <= 3: prefix = "[SKIP-RECENT]"
            snippet = f"{prefix} (ç¬¬{source_id}ç« ): {item['text']}"
            processed_snippets.append(snippet)
        
        context_block = "\n\n".join(processed_snippets)
        sys_prompt = CFG['prompts'].get('knowledge_filter_system', "è¯·ç­›é€‰æœ‰ç”¨çš„èƒŒæ™¯ä¿¡æ¯ã€‚")
        filter_prompt = f"ã€æœ¬ç« å¤§çº²ã€‘{query}\nã€æ£€ç´¢ç‰‡æ®µã€‘\n{context_block}\nã€ä»»åŠ¡ã€‘ç­›é€‰æœ‰ç”¨èƒŒæ™¯ï¼Œå¿½ç•¥[SKIP-RECENT]ï¼Œåˆå¹¶é‡å¤ï¼Œè¾“å‡ºç®€ç»ƒèƒŒæ™¯ã€‚"
        filtered_context = sync_call_llm(filter_prompt, sys_prompt, task_type="editor")
        return filtered_context, debug_info
    
    def update_chapter_summary(self, chapter_id, content):
        if len(content) < 100: return ""
        sys_prompt = CFG['prompts'].get('summary_chapter_system', "è¯·æ€»ç»“ç« èŠ‚ã€‚")
        prompt = f"è¯·é˜…è¯»ä»¥ä¸‹å°è¯´ç« èŠ‚ï¼Œç”¨ 150 å­—ä»¥å†…çš„ç¯‡å¹…ï¼Œé«˜åº¦æ¦‚æ‹¬æœ¬ç« å‘ç”Ÿçš„**æ ¸å¿ƒå‰§æƒ…**ã€**å…³é”®è½¬æŠ˜**å’Œ**é‡è¦ä¼ç¬”**ã€‚\n\nã€æ­£æ–‡ã€‘\n{content[:4000]}"
        summary = sync_call_llm(prompt, sys_prompt, task_type="writer")
        structure = self.load_structure()
        for chap in structure:
            if chap['id'] == chapter_id:
                chap['summary'] = summary
                break
        self.save_structure(structure)
        return summary

    def update_global_summary(self):
        structure = self.load_structure()
        all_summaries = []
        for chap in structure:
            if chap.get('summary'):
                all_summaries.append(f"ç¬¬{chap['id']}ç« : {chap['summary']}")
        if not all_summaries: return "æš‚æ— å‰§æƒ…ã€‚"
        combined_text = "\n".join(all_summaries)
        sys_prompt = CFG['prompts'].get('summary_book_system', "è¯·æ€»ç»“å…¨ä¹¦ã€‚")
        prompt = f"ä»¥ä¸‹æ˜¯è¿™å°±æœ¬å°è¯´ç›®å‰çš„**åˆ†ç« å‰§æƒ…æ‘˜è¦**ï¼š\n{combined_text}\nã€ä»»åŠ¡ã€‘è¯·æ ¹æ®ä»¥ä¸Šåˆ†ç« æ‘˜è¦ï¼Œå†™ä¸€ä»½**å…¨ä¹¦ç›®å‰çš„å‰§æƒ…æ€»çº²**ï¼ˆ500å­—å·¦å³ï¼‰ã€‚"
        global_summary = sync_call_llm(prompt, sys_prompt, task_type="architect")
        settings = self.load_settings()
        settings['book_summary'] = global_summary
        self.save_settings(settings)
        return global_summary
    # ã€æ–°å¢ã€‘å…¨å±€æœç´¢
    def global_search(self, term):
        if not term: return []
        results = []
        
        # 1. æœè®¾å®š (Settings)
        settings = self.load_settings()
        for k, v in settings.items():
            if isinstance(v, str) and term in v:
                results.append({"type": "setting", "key": k, "name": "ç³»ç»Ÿè®¾å®š", "preview": self._get_preview(v, term)})

        # 2. æœç« èŠ‚åˆ—è¡¨ (Title/Outline)
        structure = self.load_structure()
        for chap in structure:
            if term in chap['title']:
                results.append({"type": "chap_meta", "id": chap['id'], "field": "title", "name": f"ç¬¬{chap['id']}ç« æ ‡é¢˜", "preview": chap['title']})
            if term in chap['outline']:
                results.append({"type": "chap_meta", "id": chap['id'], "field": "outline", "name": f"ç¬¬{chap['id']}ç« å¤§çº²", "preview": self._get_preview(chap['outline'], term)})
            
            # 3. æœç« èŠ‚æ­£æ–‡ (Content)
            content = self.load_chapter_content(chap['id'])
            if term in content:
                # ç»Ÿè®¡å‡ºç°æ¬¡æ•°
                count = content.count(term)
                results.append({"type": "chap_content", "id": chap['id'], "name": f"ç¬¬{chap['id']}ç« æ­£æ–‡", "preview": self._get_preview(content, term), "count": count})

        # 4. æœæ•°æ®åº“ (Char/Item/Loc)
        chars = self.load_characters()
        for i, c in enumerate(chars):
            for k, v in c.items():
                if isinstance(v, str) and term in v:
                    results.append({"type": "char", "index": i, "field": k, "name": f"äººç‰©: {c['name']}", "preview": self._get_preview(v, term)})
        
        items = self.load_items()
        for i, it in enumerate(items):
            for k, v in it.items():
                if isinstance(v, str) and term in v:
                    results.append({"type": "item", "index": i, "field": k, "name": f"ç‰©å“: {it['name']}", "preview": self._get_preview(v, term)})
                    
        locs = self.load_locations()
        for i, l in enumerate(locs):
            for k, v in l.items():
                if isinstance(v, str) and term in v:
                    results.append({"type": "loc", "index": i, "field": k, "name": f"åœ°ç‚¹: {l['name']}", "preview": self._get_preview(v, term)})

        return results

    # è¾…åŠ©ï¼šè·å–å¸¦é«˜äº®çš„é¢„è§ˆç‰‡æ®µ
    def _get_preview(self, text, term, window=20):
        idx = text.find(term)
        if idx == -1: return text[:50]
        start = max(0, idx - window)
        end = min(len(text), idx + len(term) + window)
        return f"...{text[start:end]}..."

    # ã€æ–°å¢ã€‘å…¨å±€æ›¿æ¢
    def global_replace(self, target_items, old_term, new_term):
        # ä¸ºäº†å®‰å…¨ï¼Œé‡æ–°åŠ è½½æ‰€æœ‰æ•°æ®
        settings = self.load_settings()
        structure = self.load_structure()
        chars = self.load_characters()
        items = self.load_items()
        locs = self.load_locations()
        
        updated_files = set() # è®°å½•å“ªäº›æ–‡ä»¶è¢«ä¿®æ”¹äº†
        
        for item in target_items:
            try:
                if item['type'] == 'setting':
                    settings[item['key']] = settings[item['key']].replace(old_term, new_term)
                    updated_files.add('settings')
                
                elif item['type'] == 'chap_meta':
                    for chap in structure:
                        if chap['id'] == item['id']:
                            chap[item['field']] = chap[item['field']].replace(old_term, new_term)
                            updated_files.add('structure')
                            break
                
                elif item['type'] == 'chap_content':
                    # æ­£æ–‡æ˜¯å•ç‹¬çš„æ–‡ä»¶ï¼Œç›´æ¥è¯»å–-æ›¿æ¢-ä¿å­˜
                    content = self.load_chapter_content(item['id'])
                    new_content = content.replace(old_term, new_term)
                    self.save_chapter_content(item['id'], new_content)
                    # è¿˜éœ€è¦æ›´æ–°å‘é‡åº“å—ï¼Ÿç†è®ºä¸Šéœ€è¦ï¼Œä½†å¤ªæ…¢äº†ï¼Œå»ºè®®ç”¨æˆ·æ‰‹åŠ¨è§¦å‘æˆ–åå°æ…¢æ…¢æ›´ã€‚
                    # è¿™é‡Œä¸ºäº†é€Ÿåº¦æš‚ä¸æ›´æ–°RAGï¼Œåªæ›´æ–‡ä»¶ã€‚
                
                elif item['type'] == 'char':
                    chars[item['index']][item['field']] = chars[item['index']][item['field']].replace(old_term, new_term)
                    updated_files.add('char')
                
                elif item['type'] == 'item':
                    items[item['index']][item['field']] = items[item['index']][item['field']].replace(old_term, new_term)
                    updated_files.add('item')
                
                elif item['type'] == 'loc':
                    locs[item['index']][item['field']] = locs[item['index']][item['field']].replace(old_term, new_term)
                    updated_files.add('loc')

            except Exception as e:
                print(f"Replace error at {item}: {e}")

        # æ‰¹é‡ä¿å­˜
        if 'settings' in updated_files: self.save_settings(settings)
        if 'structure' in updated_files: self.save_structure(structure)
        if 'char' in updated_files: self.save_characters(chars)
        if 'item' in updated_files: self.save_items(items)
        if 'loc' in updated_files: self.save_locations(locs)
        
        return f"å·²åœ¨ {len(target_items)} å¤„å®Œæˆæ›¿æ¢"
    
    # 1. åˆ›å»ºå…¨é¡¹ç›®å¤‡ä»½ (ZIP)
    def create_project_backup(self, backup_dir="backups"):
        try:
            if not os.path.exists(backup_dir): os.makedirs(backup_dir)
            
            # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"novel_backup_{timestamp}"
            archive_path = os.path.join(backup_dir, filename)
            
            # æ‰“åŒ… data ç›®å½•
            if os.path.exists("data"):
                shutil.make_archive(archive_path, 'zip', "data")
                
                # æ¸…ç†æ—§å¤‡ä»½ (åªä¿ç•™æœ€è¿‘ 20 ä¸ª)
                backups = sorted(glob.glob(os.path.join(backup_dir, "*.zip")))
                if len(backups) > 20:
                    for b in backups[:-20]:
                        try: os.remove(b)
                        except: pass
                return f"å·²å¤‡ä»½: {filename}.zip"
            return "æ•°æ®ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡å¤‡ä»½"
        except Exception as e:
            return f"å¤‡ä»½å¤±è´¥: {str(e)}"

    # 2. åˆ›å»ºç« èŠ‚å¿«ç…§ (History Snapshot)
    def create_chapter_snapshot(self, chapter_id, content):
        try:
            snapshot_dir = os.path.join("data", "snapshots", str(chapter_id))
            if not os.path.exists(snapshot_dir): os.makedirs(snapshot_dir)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filepath = os.path.join(snapshot_dir, f"{timestamp}.txt")
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            
            # å•ç« åªä¿ç•™æœ€è¿‘ 50 ä¸ªå¿«ç…§ï¼Œé˜²æ­¢æ–‡ä»¶çˆ†ç‚¸
            files = sorted(glob.glob(os.path.join(snapshot_dir, "*.txt")))
            if len(files) > 50:
                for f in files[:-50]:
                    try: os.remove(f)
                    except: pass
        except Exception as e:
            print(f"Snapshot error: {e}")

    # 3. è·å–ç« èŠ‚å¿«ç…§åˆ—è¡¨
    def get_chapter_snapshots(self, chapter_id):
        snapshot_dir = os.path.join("data", "snapshots", str(chapter_id))
        if not os.path.exists(snapshot_dir): return []
        
        snapshots = []
        files = sorted(glob.glob(os.path.join(snapshot_dir, "*.txt")), reverse=True)
        for f in files:
            ts_str = os.path.basename(f).replace(".txt", "")
            try:
                dt = datetime.strptime(ts_str, "%Y%m%d_%H%M%S")
                display_time = dt.strftime("%Y-%m-%d %H:%M:%S")
            except:
                display_time = ts_str
            
            try:
                with open(f, 'r', encoding='utf-8') as file:
                    preview = file.read(100).replace("\n", " ") + "..."
            except: preview = "æ— æ³•è¯»å–å†…å®¹"
                
            snapshots.append({"filename": f, "time": display_time, "preview": preview, "raw_ts": ts_str})
        return snapshots
    # ================= ğŸ² çµæ„Ÿç”Ÿæˆ (æ–°å¢) =================

    def generate_ideas(self, type_key, context=""):
        # 1. å®šä¹‰æç¤ºè¯æ¨¡æ¿
        prompts = {
            "name_char_cn": "è¯·ç”Ÿæˆ 10 ä¸ªå¥½å¬çš„ä¸­æ–‡ç„å¹»/å¤é£äººåï¼ŒåŒ…å«ç”·å¥³ï¼Œæ ¼å¼å¦‚ï¼šå¶å‡¡ã€å§¬ç´«æœˆã€‚åªè¿”å›åå­—ï¼Œç”¨é€—å·åˆ†éš”ã€‚",
            "name_char_en": "è¯·ç”Ÿæˆ 10 ä¸ªè¥¿å¹»é£æ ¼çš„äººåï¼Œæ ¼å¼å¦‚ï¼šäºšç‘ŸÂ·æ½˜å¾·æ‹‰è´¡ã€‚åªè¿”å›åå­—ï¼Œç”¨é€—å·åˆ†éš”ã€‚",
            "name_org": "è¯·ç”Ÿæˆ 10 ä¸ªéœ¸æ°”çš„å®—æ´¾æˆ–ç»„ç»‡åç§°ï¼Œå¦‚ï¼šé­‚æ®¿ã€ç‚¸å¤©å¸®ã€‚åªè¿”å›åå­—ï¼Œç”¨é€—å·åˆ†éš”ã€‚",
            "name_skill": "è¯·ç”Ÿæˆ 10 ä¸ªç‚«é…·çš„åŠŸæ³•æˆ–æ­¦æŠ€åç§°ï¼Œå¦‚ï¼šä½›æ€’ç«è²ã€å¤§è’å›šå¤©æŒ‡ã€‚åªè¿”å›åå­—ï¼Œç”¨é€—å·åˆ†éš”ã€‚",
            "name_item": "è¯·ç”Ÿæˆ 10 ä¸ªä¼ è¯´çº§æ³•å®æˆ–ä¸¹è¯åç§°ï¼Œåªè¿”å›åå­—ï¼Œç”¨é€—å·åˆ†éš”ã€‚",
            "plot_twist": f"åŸºäºå½“å‰ä¸–ç•Œè§‚ï¼š{context[:200]}...ï¼Œè¯·æ„æ€ 3 ä¸ªæ„æƒ³ä¸åˆ°çš„å‰§æƒ…è½¬æŠ˜æˆ–çªå‘äº‹ä»¶ï¼Œç”¨äºæ‰“ç ´å½“å‰çš„å¹³æ·¡å‰§æƒ…ã€‚æ¯ä¸ªç‚¹å­ 50 å­—ä»¥å†…ã€‚",
            "gold_finger": "è¯·è„‘æ´å¤§å¼€ï¼Œç”Ÿæˆ 5 ä¸ªç‹¬ç‰¹ä¸”çˆ½ç‚¹åè¶³çš„ç½‘æ–‡â€œé‡‘æ‰‹æŒ‡â€æˆ–â€œç³»ç»Ÿâ€è®¾å®šã€‚ç®€çŸ­æè¿°ã€‚"
        }
        
        prompt = prompts.get(type_key, "è¯·éšæœºç”Ÿæˆä¸€äº›çµæ„Ÿã€‚")
        
        # 2. è°ƒç”¨ LLM (å¤ç”¨å·²æœ‰çš„ sync_call_llmï¼Œæ³¨æ„è¿™é‡Œå…¶å®åº”è¯¥ç”¨å¼‚æ­¥ï¼Œä½†ä¸ºäº†ä»£ç ç®€å•å¤ç”¨ io_bound)
        # è¿™é‡Œæˆ‘ä»¬ä¸´æ—¶æ„é€ ä¸€ä¸ª system prompt
        sys_prompt = "ä½ æ˜¯ä¸€ä¸ªç½‘æ–‡çµæ„ŸåŠ©æ‰‹ã€‚è¯·åªè¿”å›è¯·æ±‚çš„å†…å®¹ï¼Œä¸è¦åºŸè¯ã€‚"
        
        try:
            # ä½¿ç”¨å·²æœ‰çš„ client
            if not client: return "é”™è¯¯ï¼šæœªé…ç½® API Key"
            
            response = client.chat.completions.create(
                model=CFG['models'].get('writer', 'gpt-3.5-turbo'), # å€Ÿç”¨ writer æ¨¡å‹
                messages=[{"role": "system", "content": sys_prompt}, {"role": "user", "content": prompt}],
                temperature=0.9 # çµæ„Ÿéœ€è¦é«˜åˆ›é€ æ€§
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"ç”Ÿæˆå¤±è´¥: {str(e)}"
    # --- å¤§çº²æ ‘ (Blueprint) ç®¡ç† ---
    def load_outline_tree(self):
        path = os.path.join(self.root_dir, "outline_tree.json")
        if not os.path.exists(path):
            # åˆå§‹åŒ–æ ¹èŠ‚ç‚¹ï¼Œè¯»å–ç°æœ‰çš„ book_summary
            settings = self.load_settings()
            root = {
                "id": "root", "type": "book", "label": "å…¨ä¹¦æ€»çº²", 
                "desc": settings.get('book_summary', 'åœ¨æ­¤è¾“å…¥æ ¸å¿ƒçµæ„Ÿ...'), 
                "children": []
            }
            return [root]
        with open(path, 'r', encoding='utf-8') as f: return json.load(f)

    def save_outline_tree(self, data):
        with open(os.path.join(self.root_dir, "outline_tree.json"), 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)

    # --- æ ¸å¿ƒï¼šAI è£‚å˜æ¨æ¼” ---
    def ai_fractal_expand(self, node_data, context_summary):
        """
        åˆ†å½¢è£‚å˜ï¼š
        - Book -> Volumes
        - Volume -> Chapters
        """
        node_type = node_data.get('type', 'book')
        current_desc = node_data.get('desc', '')
        
        # 1. æ„é€  Prompt
        if node_type == 'book':
            target_type = 'volume'
            prompt = f"ã€æ ¸å¿ƒçµæ„Ÿã€‘{current_desc}\nã€ä»»åŠ¡ã€‘è¯·å°†è¿™æœ¬ä¹¦æ‹†åˆ†ä¸º 3-5 ä¸ªåˆ†å·ï¼ˆVolumeï¼‰ã€‚æ¯å·è¦æœ‰æ˜ç¡®çš„å‰§æƒ…é˜¶æ®µç›®æ ‡ã€‚"
        elif node_type == 'volume':
            target_type = 'chapter'
            prompt = f"ã€å…¨ä¹¦èƒŒæ™¯ã€‘{context_summary[:300]}...\nã€å½“å‰åˆ†å·ã€‘{node_data['label']}\nã€åˆ†å·å‰§æƒ…ã€‘{current_desc}\nã€ä»»åŠ¡ã€‘è¯·ä¸ºè¯¥åˆ†å·è§„åˆ’ 5-10 ä¸ªå…·ä½“ç« èŠ‚ï¼ˆChapterï¼‰ã€‚å‰§æƒ…è¦ç´§å‡‘ï¼Œè¦æœ‰èµ·æ‰¿è½¬åˆã€‚"
        else:
            return "é”™è¯¯ï¼šæ— æ³•ç»§ç»­æ‹†åˆ†ç« èŠ‚"

        sys_prompt = CFG['prompts']['architect_system']
        prompt += "\nã€æ ¼å¼è¦æ±‚ã€‘ä¸¥æ ¼è¿”å›JSONåˆ—è¡¨ï¼š[{'label': 'æ ‡é¢˜', 'desc': 'è¯¦ç»†ç»†çº²'}, ...]"

        # 2. è°ƒç”¨ LLM (å¤ç”¨ sync_call_llm)
        res = sync_call_llm(prompt, sys_prompt, task_type="architect")
        
        # 3. è§£æç»“æœ
        import uuid
        try:
            clean = res.replace("```json", "").replace("```", "").strip()
            items = json.loads(clean)
            new_nodes = []
            for item in items:
                new_nodes.append({
                    "id": str(uuid.uuid4())[:8],
                    "type": target_type,
                    "label": item['label'],
                    "desc": item['desc'],
                    "linked_id": None, # åˆå§‹æœªåŒæ­¥
                    "children": []
                })
            return new_nodes
        except Exception as e:
            return f"Error: {e} \nRaw: {res}"

    # --- æ ¸å¿ƒï¼šåŒæ­¥åˆ°æ­£å¼ç›®å½• (The Bridge) ---
    def sync_node_to_project(self, node):
        """å°†è“å›¾èŠ‚ç‚¹è½¬æ¢ä¸ºæ­£å¼çš„åˆ†å·æˆ–ç« èŠ‚"""
        if node['linked_id']: return "å·²åŒæ­¥è¿‡ï¼Œè·³è¿‡åˆ›å»º"
        
        import uuid
        
        # 1. åŒæ­¥åˆ†å·
        if node['type'] == 'volume':
            volumes = self.load_volumes()
            new_vol_id = f"vol_{str(uuid.uuid4())[:8]}"
            new_vol = {
                "id": new_vol_id, 
                "title": node['label'], 
                "order": len(volumes) + 1
            }
            volumes.append(new_vol)
            self.save_volumes(volumes)
            node['linked_id'] = new_vol_id
            return f"âœ… åˆ†å· '{node['label']}' å·²åˆ›å»º"

        # 2. åŒæ­¥ç« èŠ‚
        elif node['type'] == 'chapter':
            # å¿…é¡»æ‰¾åˆ°çˆ¶çº§åˆ†å· ID
            # æ³¨æ„ï¼šè¿™éœ€è¦å‰ç«¯ä¼ å‚æˆ–è€…åœ¨æ ‘ç»“æ„é‡Œå‘ä¸ŠæŸ¥æ‰¾ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå‡è®¾å‰ç«¯ä¼ æ¥ parent_vol_id
            # å®é™…å®ç°å»ºè®®åœ¨å‰ç«¯è°ƒç”¨æ—¶ï¼ŒæŠŠçˆ¶èŠ‚ç‚¹çš„ linked_id ä¼ è¿›æ¥
            pass 
            # (å…·ä½“å®ç°åœ¨ä¸‹é¢çš„ UI éƒ¨åˆ†å®Œå–„)
    # --- ä¸º Architect UI æä¾›æ ‘çŠ¶ç»“æ„æ•°æ® ---
    def get_novel_tree(self, app_state):
        """
        å°†æ‰å¹³çš„ volumes å’Œ structure ç»„è£…æˆ ui.tree éœ€è¦çš„åµŒå¥—æ ¼å¼
        """
        tree = []
        
        # 1. æ ¹èŠ‚ç‚¹
        root_node = {
            'id': 'root',
            'label': 'å…¨ä¹¦æ€»çº² (Root)',
            'icon': 'menu_book',
            'children': []
        }
        
        # 2. æ„å»ºåˆ†å·
        # å‡è®¾ app_state.volumes æ˜¯åˆ—è¡¨ [{'id': 1, 'title': '...'}, ...]
        # å‡è®¾ app_state.structure æ˜¯åˆ—è¡¨ [{'id': 1, 'volume_id': 1, 'title': '...'}, ...]
        
        for vol in app_state.volumes:
            vol_node = {
                'id': f"vol_{vol['id']}", # åŠ ä¸Šå‰ç¼€é˜²æ­¢IDå†²çª
                'label': vol['title'],
                'icon': 'inventory_2',
                'children': [],
                '_raw': vol # æš‚å­˜åŸå§‹æ•°æ®æ–¹ä¾¿åç»­è·å–
            }
            
            # 3. æ„å»ºè¯¥å·ä¸‹çš„ç« èŠ‚
            vol_chapters = [c for c in app_state.structure if str(c.get('volume_id')) == str(vol['id'])]
            for chap in vol_chapters:
                chap_node = {
                    'id': f"chap_{chap['id']}",
                    'label': chap['title'],
                    'icon': 'article',
                    '_raw': chap
                }
                vol_node['children'].append(chap_node)
            
            root_node['children'].append(vol_node)
            
        tree.append(root_node)
        return tree

    # --- è·å–èŠ‚ç‚¹ä¸Šä¸‹æ–‡ (ç”¨äºå³ä¾§é¢æ¿æ¸²æŸ“) ---
    def get_node_context(self, node_id, app_state):
        """
        è¿”å›: (node_type, context_dict, raw_data)
        """
        # å®šä¹‰é»˜è®¤çš„å®‰å…¨è¿”å› (å…œåº•ç­–ç•¥)
        safe_ctx = {
            'self_info': 'æš‚æ— è¯¦ç»†ä¿¡æ¯ (å¯èƒ½æ˜¯æœªåŒæ­¥çš„èŠ‚ç‚¹æˆ–æ•°æ®å·²å˜æ›´)',
            'parent_info': None
        }
        
        try:
            settings = self.load_settings()
            
            # === Case 1: æ ¹èŠ‚ç‚¹ ===
            if node_id == 'root':
                ctx = {
                    'self_info': settings.get('book_summary', 'æš‚æ— å…¨ä¹¦ç®€ä»‹'),
                    'parent_info': None
                }
                return 'root', ctx, {'title': 'å…¨ä¹¦æ€»çº²'}
                
            # === Case 2: åˆ†å·èŠ‚ç‚¹ ===
            if str(node_id).startswith('vol_'):
                # ã€ä¿®å¤ã€‘åªæ›¿æ¢ç¬¬ä¸€ä¸ª 'vol_'ï¼Œæˆ–è€…ç›´æ¥ç”¨åˆ‡ç‰‡
                # é”™è¯¯å†™æ³•: real_id = node_id.replace('vol_', '') 
                # æ­£ç¡®å†™æ³•: 
                real_id = node_id.replace('vol_', '', 1) 
                
                # æˆ–è€…æ›´ç¨³å¦¥çš„åˆ‡ç‰‡å†™æ³• (å› ä¸ºå‰ç¼€å›ºå®šé•¿åº¦æ˜¯4)
                # real_id = node_id[4:] 

                # æŸ¥æ‰¾åˆ†å·æ•°æ®
                vol_data = next((v for v in app_state.volumes if str(v['id']) == str(real_id)), None)
                
                if not vol_data: 
                    return 'unknown', safe_ctx, {}
                
                ctx = {
                    'self_info': vol_data.get('desc', 'ï¼ˆè¯¥åˆ†å·æš‚æ— è¯¦ç»†æè¿°ï¼‰'),
                    'parent_info': f"**å…¨ä¹¦ç›®æ ‡**ï¼š\n{settings.get('book_summary', '')[:100]}..."
                }
                return 'volume', ctx, vol_data
                
            # === Case 3: ç« èŠ‚èŠ‚ç‚¹ ===
            if str(node_id).startswith('chap_'):
                # ã€ä¿®å¤ã€‘åŒç†ï¼Œåªæ›¿æ¢ç¬¬ä¸€ä¸ª 'chap_'
                real_id = node_id.replace('chap_', '', 1)
                
                chap_data = next((c for c in app_state.structure if str(c['id']) == str(real_id)), None)
                
                if not chap_data: 
                    return 'unknown', safe_ctx, {} # <--- ä¿®å¤ç‚¹ï¼šè¿”å› safe_ctx
                
                # æ‰¾çˆ¶çº§åˆ†å·ä¿¡æ¯
                parent_vol = next((v for v in app_state.volumes if str(v['id']) == str(chap_data.get('volume_id'))), None)
                parent_title = parent_vol['title'] if parent_vol else "æœªçŸ¥åˆ†å·"
                parent_desc = parent_vol.get('desc', parent_title) if parent_vol else ""
                
                ctx = {
                    'self_info': chap_data.get('outline', 'æš‚æ— å¤§çº²'),
                    'parent_info': f"**æ‰€å±åˆ†å·**ï¼š{parent_title}\n**åˆ†å·ç›®æ ‡**ï¼š{parent_desc[:100]}..."
                }
                return 'chapter', ctx, chap_data
                
            # === Case 4: æœªçŸ¥/å…œåº• ===
            return 'unknown', safe_ctx, {}

        except Exception as e:
            print(f"Error in get_node_context: {e}")
            return 'error', safe_ctx, {}

# ================= å‘é‡åº“ç®¡ç†å™¨ (RAG) =================
class MemoryManager:
    def __init__(self, book_name="default"):
        self.root_dir = "chroma_db_storage" 
        if not os.path.exists(self.root_dir): os.makedirs(self.root_dir)
        
        self.client = chromadb.PersistentClient(path=self.root_dir)
        self.embedding_fn = embedding_functions.DefaultEmbeddingFunction()
        
        # ã€ä¿®å¤æ ¸å¿ƒã€‘ä½¿ç”¨ MD5 å“ˆå¸Œç”Ÿæˆåˆæ³•çš„ Collection åç§°
        # æ— è®º book_name æ˜¯ä¸­æ–‡ã€è‹±æ–‡è¿˜æ˜¯ç‰¹æ®Šå­—ç¬¦ï¼Œhash æ°¸è¿œæ˜¯åˆæ³•çš„å­—æ¯æ•°å­—ç»„åˆ
        hash_object = hashlib.md5(book_name.encode('utf-8'))
        hex_dig = hash_object.hexdigest() # ç”Ÿæˆç±»ä¼¼ 'e10adc3949ba59abbe56e057f20f883e'
        
        # åŠ ä¸Šå‰ç¼€ï¼Œç¡®ä¿ä»¥å­—æ¯å¼€å¤´ (ChromaDB è¦æ±‚)
        safe_name = f"novel_{hex_dig}"
        
        # æ‰“å°ä¸€ä¸‹ï¼Œæ–¹ä¾¿è°ƒè¯•çœ‹åˆ°ä¸­æ–‡ä¹¦åå¯¹åº”ä»€ä¹ˆå“ˆå¸Œ
        print(f"[RAG] ä¹¦ç± '{book_name}' å¯¹åº”å‘é‡åº“: {safe_name}")

        self.collection = self.client.get_or_create_collection(
            name=safe_name, 
            embedding_function=self.embedding_fn
        )

    def add_chapter_memory(self, chapter_id, content):
        self.delete_chapter_memory(chapter_id)
        chunk_size = CFG.get('chunk_size', 500)
        step = chunk_size - CFG.get('overlap', 100)
        chunks = [content[i:i+chunk_size] for i in range(0, len(content), step) if len(content[i:i+chunk_size]) > 50]
        if not chunks: return
        ids = [f"ch_{chapter_id}_{i}" for i in range(len(chunks))]
        metadatas = [{"chapter_id": chapter_id, "chunk_index": i} for i in range(len(chunks))]
        self.collection.upsert(documents=chunks, metadatas=metadatas, ids=ids)

    def delete_chapter_memory(self, chapter_id):
        try: self.collection.delete(where={"chapter_id": chapter_id})
        except Exception as e: print(f"[RAG Error] {e}")

    def query_related_memory(self, query_text, n_results=5, threshold=1.5, exclude_chapter_id=None):
        where_filter = None
        if exclude_chapter_id is not None:
            where_filter = {"chapter_id": {"$ne": exclude_chapter_id}}
        try:
            if self.collection.count() == 0: return [], []
            results = self.collection.query(query_texts=[query_text], n_results=n_results, include=['documents', 'distances', 'metadatas'], where=where_filter)
        except Exception as e: return [], []

        valid_docs = []
        debug_info = []
        if results['documents'] and results['documents'][0]:
            for doc, dist, meta in zip(results['documents'][0], results['distances'][0], results['metadatas'][0]):
                is_valid = dist < threshold
                debug_info.append({"text": doc, "distance": round(dist, 4), "source": f"ç¬¬{meta['chapter_id']}ç« ", "valid": is_valid})
                if is_valid: valid_docs.append(doc)
        return valid_docs, debug_info

# ================= LLM è°ƒç”¨æ¥å£ =================

def sync_call_llm(prompt, system_prompt, task_type="writer"):
    model_name = CFG['models'].get(task_type, "deepseek-chat")
    temperature = CFG['temperatures'].get(task_type, 1.3)
    print(f"\n[LLM Router] ä»»åŠ¡: {task_type} | æ¨¡å‹: {model_name}")
    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": prompt}],
            stream=False,
            temperature=temperature
        )
        return response.choices[0].message.content
    except Exception as e: return f"Error: {str(e)}"

def sync_rewrite_llm(selected_text, context_pre, context_post, instruction):
    task_type = "editor"
    model_name = CFG['models'].get(task_type, "deepseek-chat")
    temperature = CFG['temperatures'].get(task_type, 0.7)
    prompt = f"ã€ä»»åŠ¡ã€‘é‡å†™æ–‡æœ¬ã€‚\nã€ä¸Šæ–‡ã€‘...{context_pre[-500:]}\nã€å¾…ä¿®æ”¹ã€‘{selected_text}\nã€ä¸‹æ–‡ã€‘{context_post[:500]}...\nã€è¦æ±‚ã€‘{instruction}"
    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "system", "content": "ä¸“ä¸šç¼–è¾‘"}, {"role": "user", "content": prompt}],
            stream=False,
            temperature=temperature
        )
        return response.choices[0].message.content
    except Exception as e: return f"Error: {str(e)}"

def sync_review_chapter(content, context_str):
    task_type = "reviewer"
    model_name = CFG['models'].get(task_type, "deepseek-chat")
    temperature = CFG['temperatures'].get(task_type, 0.5)
    sys_prompt = CFG['prompts'].get('reviewer_system', "ä½ æ˜¯ä¸€ä¸ªä¸¥å‰çš„ç¼–è¾‘ã€‚")
    prompt = f"ã€å¾…å®¡æŸ¥æ­£æ–‡ã€‘\n{content}\nã€å‚è€ƒè®¾å®šã€‘\n{context_str}\nã€ä»»åŠ¡ã€‘å®¡æŸ¥é€»è¾‘ä¸€è‡´æ€§ã€å‰§æƒ…èŠ‚å¥ã€æ–‡ç¬”ã€‚è¾“å‡ºMarkdownæŠ¥å‘Šã€‚"
    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "system", "content": sys_prompt}, {"role": "user", "content": prompt}],
            stream=False,
            temperature=temperature
        )
        return response.choices[0].message.content
    except Exception as e: return f"Error: {str(e)}"

def sync_analyze_time(content, prev_time_label):
    task_type = "timekeeper"
    model_name = CFG['models'].get(task_type, "deepseek-chat")
    temperature = CFG['temperatures'].get(task_type, 0.1)
    sys_prompt = CFG['prompts'].get('timekeeper_system', "ä½ æ˜¯ä¸€ä¸ªæ—¶é—´è®°å½•å‘˜ã€‚")
    prompt = f"ã€ä¸Šä¸€ç« æ—¶é—´ã€‘{prev_time_label}\nã€æœ¬ç« æ­£æ–‡ã€‘{content[:3000]}...\nã€ä»»åŠ¡ã€‘1.åˆ†ææ—¶é—´æµé€ 2.æ¨ç®—å½“å‰æ—¶é—´ 3.æå–äº‹ä»¶\nã€è¾“å‡ºæ ¼å¼ã€‘ä¸¥æ ¼JSON: {{\"label\": \"...\", \"duration\": \"...\", \"events\": [\"...\"]}}"
    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "system", "content": sys_prompt}, {"role": "user", "content": prompt}],
            stream=False,
            temperature=temperature
        )
        return response.choices[0].message.content
    except Exception as e: return f"Error: {str(e)}"

# ã€ä¿®æ”¹ã€‘çŠ¶æ€åˆ†ææ¥å£ï¼šå¢åŠ æå–â€œåœ°ç‚¹è¿æ¥â€çš„æŒ‡ä»¤
def sync_analyze_state(content, current_data_summary):
    task_type = "auditor"
    model_name = CFG['models'].get(task_type, "deepseek-reasoner")
    temperature = CFG['temperatures'].get(task_type, 1.0)
    sys_prompt = CFG['prompts'].get('auditor_system', "ä½ æ˜¯ä¸€ä¸ªä¸–ç•Œè§‚ç®¡ç†å‘˜ã€‚")
    
    prompt = f"""
    ã€å½“å‰æ­£æ–‡ã€‘
    {content[:4000]}...
    
    ã€ç°æœ‰æ•°æ®åº“æ‘˜è¦ã€‘
    {current_data_summary}
    
    ã€ä»»åŠ¡ã€‘
    è¯·åˆ†ææ­£æ–‡ï¼Œæ£€æµ‹ä»¥ä¸‹å˜åŒ–ï¼š
    1. **äººç‰©çŠ¶æ€å˜æ›´**ï¼šç­‰çº§ã€çŠ¶æ€(å—ä¼¤/æ­»äº¡)ã€æ‰€å±åŠ¿åŠ›ã€‚
    2. **ç‰©å“å˜æ›´**ï¼šæŒæœ‰è€…è½¬ç§»ã€ç‰©å“çŠ¶æ€å˜åŒ–ã€æ–°ç‰©å“è·å¾—ã€‚
    3. **æ–°å®ä½“**ï¼šæ˜¯å¦å‡ºç°äº†**é‡è¦**çš„æ–°äººç‰©ã€æ–°ç‰©å“æˆ–æ–°åœ°ç‚¹ï¼Ÿ
    4. **äººé™…å…³ç³»å˜æ›´**ï¼šæå–æ–°å…³ç³»ï¼ˆå¦‚æ‹œå¸ˆã€ç»“ä»‡ï¼‰æˆ–å…³ç³»å˜åŒ–ã€‚
    5. **åœ°ç‚¹è¿æ¥ (æ–°)**ï¼šä¸»è§’æ˜¯å¦ä»ä¸€ä¸ªåœ°ç‚¹ç§»åŠ¨åˆ°äº†å¦ä¸€ä¸ªåœ°ç‚¹ï¼Ÿå¦‚æœæ˜¯ï¼Œè¿™æ„å‘³ç€ä¸¤ä¸ªåœ°ç‚¹æ˜¯è¿é€šçš„ã€‚æå–è¿™ç§æ‹“æ‰‘å…³ç³»ã€‚
    
    ã€è¾“å‡ºæ ¼å¼ã€‘
    ä¸¥æ ¼ JSON æ ¼å¼ï¼Œå­—æ®µå¦‚ä¸‹ï¼š
    {{
        "char_updates": [{{"name": "...", "field": "...", "new_value": "...", "reason": "..."}}],
        "item_updates": [{{"name": "...", "field": "...", "new_value": "..."}}],
        "new_chars": [{{"name": "...", "gender": "...", "role": "...", "status": "...", "bio": "..."}}],
        "new_items": [{{"name": "...", "type": "...", "owner": "...", "desc": "..."}}],
        "new_locs": [{{"name": "...", "faction": "...", "desc": "..."}}],
        "relation_updates": [
            {{"source": "ä¸»åŠ¨æ–¹", "target": "è¢«åŠ¨æ–¹", "type": "å…³ç³»ç±»å‹", "desc": "è¯´æ˜"}}
        ],
        "loc_connections": [
            {{"source": "åœ°ç‚¹A", "target": "åœ°ç‚¹B", "desc": "ç§»åŠ¨/è¿æ¥è¯´æ˜"}}
        ]
    }}
    """
    print(f"\n[LLM Router] ä»»åŠ¡: State Auditor | æ¨¡å‹: {model_name}")
    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "system", "content": sys_prompt}, {"role": "user", "content": prompt}],
            stream=False,
            temperature=temperature
        )
        return response.choices[0].message.content
    except Exception as e: return f"Error: {str(e)}"

# ã€ä¿®æ”¹ã€‘åº”ç”¨å˜æ›´ï¼šå¢åŠ å¤„ç†â€œåœ°ç‚¹è¿æ¥â€çš„é€»è¾‘
def apply_state_changes(novel_manager, changes):
    logs = []
    
    # 1. æ›´æ–°äººç‰© (ä¿æŒä¸å˜)
    chars = novel_manager.load_characters()
    for update in changes.get('char_updates', []):
        for char in chars:
            if char['name'] == update['name']:
                char[update['field']] = update['new_value']
                logs.append(f"æ›´æ–°äººç‰© [{char['name']}]: {update['field']} -> {update['new_value']}")
    
    for new_char in changes.get('new_chars', []):
        if not any(c['name'] == new_char['name'] for c in chars):
            if 'relations' not in new_char: new_char['relations'] = []
            chars.append(new_char)
            logs.append(f"æ–°å¢äººç‰©: {new_char['name']}")
            
    for rel in changes.get('relation_updates', []):
        source_char = next((c for c in chars if c['name'] == rel['source']), None)
        if source_char:
            existing_rel = next((r for r in source_char['relations'] if r['target'] == rel['target']), None)
            if existing_rel:
                existing_rel['type'] = rel['type']
                logs.append(f"æ›´æ–°å…³ç³»: {rel['source']} -> {rel['target']} ({rel['type']})")
            else:
                source_char['relations'].append({"target": rel['target'], "type": rel['type']})
                logs.append(f"æ–°å¢å…³ç³»: {rel['source']} -> {rel['target']} ({rel['type']})")
    
    novel_manager.save_characters(chars)

    # 2. æ›´æ–°ç‰©å“ (ä¿æŒä¸å˜)
    items = novel_manager.load_items()
    for update in changes.get('item_updates', []):
        for item in items:
            if item['name'] == update['name']:
                item[update['field']] = update['new_value']
                logs.append(f"æ›´æ–°ç‰©å“ [{item['name']}]: {update['field']} -> {update['new_value']}")
    for new_item in changes.get('new_items', []):
        if not any(i['name'] == new_item['name'] for i in items):
            items.append(new_item)
            logs.append(f"æ–°å¢ç‰©å“: {new_item['name']}")
    novel_manager.save_items(items)

    # 3. æ›´æ–°åœ°ç‚¹ (å¢åŠ è¿æ¥å¤„ç†é€»è¾‘)
    locs = novel_manager.load_locations()
    
    # A. å…ˆå¤„ç†æ–°åœ°ç‚¹ (é˜²æ­¢è¿æ¥æ—¶æ‰¾ä¸åˆ°åœ°ç‚¹)
    for new_loc in changes.get('new_locs', []):
        if not any(l['name'] == new_loc['name'] for l in locs):
            if 'neighbors' not in new_loc: new_loc['neighbors'] = []
            locs.append(new_loc)
            logs.append(f"æ–°å¢åœ°ç‚¹: {new_loc['name']}")
    
    # B. å¤„ç†è¿æ¥å…³ç³»
    for conn in changes.get('loc_connections', []):
        loc_a = next((l for l in locs if l['name'] == conn['source']), None)
        loc_b = next((l for l in locs if l['name'] == conn['target']), None)
        
        if loc_a and loc_b:
            # ç¡®ä¿æœ‰ neighbors å­—æ®µ
            if 'neighbors' not in loc_a: loc_a['neighbors'] = []
            if 'neighbors' not in loc_b: loc_b['neighbors'] = []
            
            # åŒå‘æ·»åŠ  (é¿å…é‡å¤)
            added = False
            if conn['target'] not in loc_a['neighbors']:
                loc_a['neighbors'].append(conn['target'])
                added = True
            if conn['source'] not in loc_b['neighbors']:
                loc_b['neighbors'].append(conn['source'])
                added = True
            
            if added:
                logs.append(f"æ–°å¢åœ°å›¾è¿æ¥: {conn['source']} â†”ï¸ {conn['target']}")

    novel_manager.save_locations(locs)

    return logs

def export_full_novel(novel_manager):
    structure = novel_manager.load_structure()
    full_text = [f"ã€ŠAI ç”Ÿæˆé•¿ç¯‡å°è¯´ã€‹\næ€»å­—æ•°ï¼š{novel_manager.get_total_word_count()}\n{'='*30}\n\n"]
    for chap in structure:
        title = f"ç¬¬{chap['id']}ç«  {chap['title']}"
        content = novel_manager.load_chapter_content(chap['id'])
        full_text.extend([title, "-" * 20, content, "\n\n"])
    return "\n".join(full_text)