import json
import os
import chromadb
from chromadb.utils import embedding_functions
from openai import OpenAI
import shutil # <--- æ–°å¢
import glob   # <--- æ–°å¢
from datetime import datetime # <--- å¿…é¡»åŠ è¿™ä¸€è¡Œï¼

# ================= é…ç½®åŠ è½½ =================
def load_config():
    # ä¼˜å…ˆè¯»å– config.jsonï¼Œä¸å­˜åœ¨åˆ™è¯»å– config.example.jsonï¼Œå†æ²¡æœ‰åˆ™è¿”å›ç©º
    if os.path.exists("config.json"):
        with open("config.json", 'r', encoding='utf-8') as f:
            return json.load(f)
    elif os.path.exists("config.example.json"):
        with open("config.example.json", 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}

CFG = load_config()
# åˆå§‹åŒ–å…¨å±€ client
client = OpenAI(api_key=CFG.get('api_key'), base_url=CFG.get('base_url'))

# ã€æ–°å¢ã€‘ä¿å­˜é…ç½®å¹¶çƒ­é‡è½½
def save_global_config(new_config):
    global CFG, client
    try:
        # 1. å†™å…¥æ–‡ä»¶
        with open("config.json", 'w', encoding='utf-8') as f:
            json.dump(new_config, f, ensure_ascii=False, indent=4)
        
        # 2. çƒ­æ›´æ–°å†…å­˜ä¸­çš„é…ç½®
        CFG.update(new_config)
        
        # 3. é‡ç½® OpenAI å®¢æˆ·ç«¯ (è¿™ä¸€æ­¥å¾ˆå…³é”®ï¼Œå¦åˆ™æ”¹äº† Key ä¸ç”Ÿæ•ˆ)
        client = OpenAI(api_key=CFG.get('api_key'), base_url=CFG.get('base_url'))
        
        return "âœ… é…ç½®å·²ä¿å­˜ï¼Œç³»ç»Ÿå·²çƒ­é‡è½½"
    except Exception as e:
        return f"âŒ ä¿å­˜å¤±è´¥: {str(e)}"

# ================= å°è¯´ç®¡ç†å™¨ (æ•°æ®å±‚) =================
class NovelManager:
    def __init__(self):
        self.root_dir = CFG.get('project_dir', 'MyNovel_Data')
        self.chapters_dir = os.path.join(self.root_dir, "chapters")
        self.setting_file = os.path.join(self.root_dir, "setting.json")
        self.char_file = os.path.join(self.root_dir, "characters.json")
        self.item_file = os.path.join(self.root_dir, "items.json")
        self.loc_file = os.path.join(self.root_dir, "locations.json")
        self.structure_file = os.path.join(self.root_dir, "structure.json")
        self.volume_file = os.path.join(self.root_dir, "volumes.json")
        self._init_fs()

    def _init_fs(self):
        if not os.path.exists(self.chapters_dir): os.makedirs(self.chapters_dir)
        
        if not os.path.exists(self.setting_file):
            with open(self.setting_file, 'w', encoding='utf-8') as f:
                json.dump({"world_view": "", "characters": "", "book_summary": ""}, f, ensure_ascii=False, indent=4)
        
        if not os.path.exists(self.char_file):
            default_chars = [{
                "name": "ä¸»è§’", "gender": "ç”·", "role": "ä¸»è§’", 
                "status": "å­˜æ´»", "bio": "æ€§æ ¼åšæ¯…ã€‚", "relations": []
            }]
            with open(self.char_file, 'w', encoding='utf-8') as f:
                json.dump(default_chars, f, ensure_ascii=False, indent=4)

        if not os.path.exists(self.item_file):
            with open(self.item_file, 'w', encoding='utf-8') as f: json.dump([], f)
        
        if not os.path.exists(self.loc_file):
            with open(self.loc_file, 'w', encoding='utf-8') as f: json.dump([], f)

        if not os.path.exists(self.volume_file):
            default_vol = [{"id": "vol_default", "title": "æ­£æ–‡å·", "order": 1}]
            with open(self.volume_file, 'w', encoding='utf-8') as f:
                json.dump(default_vol, f, ensure_ascii=False, indent=4)

        if not os.path.exists(self.structure_file):
            default_structure = [{
                "id": 1, 
                "title": "ç¬¬ä¸€ç« ", 
                "volume_id": "vol_default", 
                "outline": "å¼€å±€ã€‚", 
                "summary": "", 
                "time_info": {"label": "æ•…äº‹å¼€å§‹", "duration": "0", "events": []}
            }]
            with open(self.structure_file, 'w', encoding='utf-8') as f:
                json.dump(default_structure, f, ensure_ascii=False, indent=4)

    # --- åŸºç¡€è¯»å†™ ---
    def load_settings(self):
        try:
            with open(self.setting_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return {}

    def save_settings(self, data):
        with open(self.setting_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
    
    def load_characters(self):
        try:
            with open(self.char_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                for char in data:
                    if 'relations' not in char: char['relations'] = []
                return data
        except: return []

    def save_characters(self, data):
        with open(self.char_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)

    def load_items(self):
        try:
            with open(self.item_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return []

    def save_items(self, data):
        with open(self.item_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)

    def load_locations(self):
        try:
            with open(self.loc_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return []

    def save_locations(self, data):
        with open(self.loc_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)

    def load_volumes(self):
        try:
            with open(self.volume_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return []

    def save_volumes(self, data):
        with open(self.volume_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)

    def load_structure(self):
        try:
            with open(self.structure_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                for chap in data:
                    if 'time_info' not in chap:
                        chap['time_info'] = {"label": "æœªçŸ¥æ—¶é—´", "duration": "-", "events": []}
                    if 'volume_id' not in chap:
                        chap['volume_id'] = "vol_default"
                return data
        except: return []

    def save_structure(self, data):
        with open(self.structure_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
    
    def save_chapter_content(self, chapter_id, content):
        with open(os.path.join(self.chapters_dir, f"{chapter_id}.txt"), 'w', encoding='utf-8') as f:
            f.write(content)
    
    def load_chapter_content(self, chapter_id):
        path = os.path.join(self.chapters_dir, f"{chapter_id}.txt")
        return open(path, 'r', encoding='utf-8').read() if os.path.exists(path) else ""
    
    def delete_chapter(self, chapter_id):
        path = os.path.join(self.chapters_dir, f"{chapter_id}.txt")
        if os.path.exists(path): os.remove(path)

    def get_total_word_count(self):
        structure = self.load_structure()
        total = 0
        for chap in structure:
            content = self.load_chapter_content(chap['id'])
            total += len(content)
        return total

    def get_relevant_context(self, text_context):
        chars = self.load_characters()
        items = self.load_items()
        locs = self.load_locations()
        
        active_info = []
        active_names = []

        found_chars = [c for c in chars if c['name'] in text_context]
        if not found_chars and chars: found_chars.append(chars[0])
        
        if found_chars:
            active_info.append("ã€ç›¸å…³äººç‰©ã€‘")
            for c in found_chars:
                rels = ", ".join([f"{r['type']}->{r['target']}" for r in c.get('relations', [])])
                rel_str = f" [å…³ç³»: {rels}]" if rels else ""
                active_info.append(f"- {c['name']} ({c['gender']}/{c['role']}/{c['status']}){rel_str}: {c['bio']}")
                active_names.append(c['name'])

        found_items = [i for i in items if i['name'] in text_context]
        if found_items:
            active_info.append("ã€ç›¸å…³ç‰©å“ã€‘")
            for i in found_items:
                active_info.append(f"- {i['name']} ({i['type']}/æŒæœ‰:{i['owner']}): {i['desc']}")
                active_names.append(i['name'])

        found_locs = [l for l in locs if l['name'] in text_context]
        if found_locs:
            active_info.append("ã€ç›¸å…³åœ°ç‚¹ã€‘")
            for l in found_locs:
                active_info.append(f"- {l['name']} ({l['faction']}): {l['desc']}")
                active_names.append(l['name'])

        return "\n".join(active_info), active_names

    def smart_rag_pipeline(self, query, current_chapter_id, memory_manager):
        print(f"\n[Smart RAG] å¯åŠ¨æ™ºèƒ½æ£€ç´¢: {query[:20]}...")
        raw_docs, debug_info = memory_manager.query_related_memory(
            query, n_results=8, threshold=1.6, exclude_chapter_id=current_chapter_id
        )
        if not raw_docs: return "ï¼ˆæ— ç›¸å…³å†å²è®°å¿†ï¼‰", []

        processed_snippets = []
        for item in debug_info:
            source_id = int(item['source'].replace("ç¬¬", "").replace("ç« ", ""))
            distance = current_chapter_id - source_id
            prefix = "[REF]"
            if 1 <= distance <= 3: prefix = "[SKIP-RECENT]"
            snippet = f"{prefix} (ç¬¬{source_id}ç« ): {item['text']}"
            processed_snippets.append(snippet)
        
        context_block = "\n\n".join(processed_snippets)
        sys_prompt = CFG['prompts'].get('knowledge_filter_system', "è¯·ç­›é€‰æœ‰ç”¨çš„èƒŒæ™¯ä¿¡æ¯ã€‚")
        filter_prompt = f"ã€æœ¬ç« å¤§çº²ã€‘{query}\nã€æ£€ç´¢ç‰‡æ®µã€‘\n{context_block}\nã€ä»»åŠ¡ã€‘ç­›é€‰æœ‰ç”¨èƒŒæ™¯ï¼Œå¿½ç•¥[SKIP-RECENT]ï¼Œåˆå¹¶é‡å¤ï¼Œè¾“å‡ºç®€ç»ƒèƒŒæ™¯ã€‚"
        filtered_context = sync_call_llm(filter_prompt, sys_prompt, task_type="editor")
        return filtered_context, debug_info
    
    def update_chapter_summary(self, chapter_id, content):
        if len(content) < 100: return ""
        sys_prompt = CFG['prompts'].get('summary_chapter_system', "è¯·æ€»ç»“ç« èŠ‚ã€‚")
        prompt = f"è¯·é˜…è¯»ä»¥ä¸‹å°è¯´ç« èŠ‚ï¼Œç”¨ 150 å­—ä»¥å†…çš„ç¯‡å¹…ï¼Œé«˜åº¦æ¦‚æ‹¬æœ¬ç« å‘ç”Ÿçš„**æ ¸å¿ƒå‰§æƒ…**ã€**å…³é”®è½¬æŠ˜**å’Œ**é‡è¦ä¼ç¬”**ã€‚\n\nã€æ­£æ–‡ã€‘\n{content[:4000]}"
        summary = sync_call_llm(prompt, sys_prompt, task_type="writer")
        structure = self.load_structure()
        for chap in structure:
            if chap['id'] == chapter_id:
                chap['summary'] = summary
                break
        self.save_structure(structure)
        return summary

    def update_global_summary(self):
        structure = self.load_structure()
        all_summaries = []
        for chap in structure:
            if chap.get('summary'):
                all_summaries.append(f"ç¬¬{chap['id']}ç« : {chap['summary']}")
        if not all_summaries: return "æš‚æ— å‰§æƒ…ã€‚"
        combined_text = "\n".join(all_summaries)
        sys_prompt = CFG['prompts'].get('summary_book_system', "è¯·æ€»ç»“å…¨ä¹¦ã€‚")
        prompt = f"ä»¥ä¸‹æ˜¯è¿™å°±æœ¬å°è¯´ç›®å‰çš„**åˆ†ç« å‰§æƒ…æ‘˜è¦**ï¼š\n{combined_text}\nã€ä»»åŠ¡ã€‘è¯·æ ¹æ®ä»¥ä¸Šåˆ†ç« æ‘˜è¦ï¼Œå†™ä¸€ä»½**å…¨ä¹¦ç›®å‰çš„å‰§æƒ…æ€»çº²**ï¼ˆ500å­—å·¦å³ï¼‰ã€‚"
        global_summary = sync_call_llm(prompt, sys_prompt, task_type="architect")
        settings = self.load_settings()
        settings['book_summary'] = global_summary
        self.save_settings(settings)
        return global_summary
    # ã€æ–°å¢ã€‘å…¨å±€æœç´¢
    def global_search(self, term):
        if not term: return []
        results = []
        
        # 1. æœè®¾å®š (Settings)
        settings = self.load_settings()
        for k, v in settings.items():
            if isinstance(v, str) and term in v:
                results.append({"type": "setting", "key": k, "name": "ç³»ç»Ÿè®¾å®š", "preview": self._get_preview(v, term)})

        # 2. æœç« èŠ‚åˆ—è¡¨ (Title/Outline)
        structure = self.load_structure()
        for chap in structure:
            if term in chap['title']:
                results.append({"type": "chap_meta", "id": chap['id'], "field": "title", "name": f"ç¬¬{chap['id']}ç« æ ‡é¢˜", "preview": chap['title']})
            if term in chap['outline']:
                results.append({"type": "chap_meta", "id": chap['id'], "field": "outline", "name": f"ç¬¬{chap['id']}ç« å¤§çº²", "preview": self._get_preview(chap['outline'], term)})
            
            # 3. æœç« èŠ‚æ­£æ–‡ (Content)
            content = self.load_chapter_content(chap['id'])
            if term in content:
                # ç»Ÿè®¡å‡ºç°æ¬¡æ•°
                count = content.count(term)
                results.append({"type": "chap_content", "id": chap['id'], "name": f"ç¬¬{chap['id']}ç« æ­£æ–‡", "preview": self._get_preview(content, term), "count": count})

        # 4. æœæ•°æ®åº“ (Char/Item/Loc)
        chars = self.load_characters()
        for i, c in enumerate(chars):
            for k, v in c.items():
                if isinstance(v, str) and term in v:
                    results.append({"type": "char", "index": i, "field": k, "name": f"äººç‰©: {c['name']}", "preview": self._get_preview(v, term)})
        
        items = self.load_items()
        for i, it in enumerate(items):
            for k, v in it.items():
                if isinstance(v, str) and term in v:
                    results.append({"type": "item", "index": i, "field": k, "name": f"ç‰©å“: {it['name']}", "preview": self._get_preview(v, term)})
                    
        locs = self.load_locations()
        for i, l in enumerate(locs):
            for k, v in l.items():
                if isinstance(v, str) and term in v:
                    results.append({"type": "loc", "index": i, "field": k, "name": f"åœ°ç‚¹: {l['name']}", "preview": self._get_preview(v, term)})

        return results

    # è¾…åŠ©ï¼šè·å–å¸¦é«˜äº®çš„é¢„è§ˆç‰‡æ®µ
    def _get_preview(self, text, term, window=20):
        idx = text.find(term)
        if idx == -1: return text[:50]
        start = max(0, idx - window)
        end = min(len(text), idx + len(term) + window)
        return f"...{text[start:end]}..."

    # ã€æ–°å¢ã€‘å…¨å±€æ›¿æ¢
    def global_replace(self, target_items, old_term, new_term):
        # ä¸ºäº†å®‰å…¨ï¼Œé‡æ–°åŠ è½½æ‰€æœ‰æ•°æ®
        settings = self.load_settings()
        structure = self.load_structure()
        chars = self.load_characters()
        items = self.load_items()
        locs = self.load_locations()
        
        updated_files = set() # è®°å½•å“ªäº›æ–‡ä»¶è¢«ä¿®æ”¹äº†
        
        for item in target_items:
            try:
                if item['type'] == 'setting':
                    settings[item['key']] = settings[item['key']].replace(old_term, new_term)
                    updated_files.add('settings')
                
                elif item['type'] == 'chap_meta':
                    for chap in structure:
                        if chap['id'] == item['id']:
                            chap[item['field']] = chap[item['field']].replace(old_term, new_term)
                            updated_files.add('structure')
                            break
                
                elif item['type'] == 'chap_content':
                    # æ­£æ–‡æ˜¯å•ç‹¬çš„æ–‡ä»¶ï¼Œç›´æ¥è¯»å–-æ›¿æ¢-ä¿å­˜
                    content = self.load_chapter_content(item['id'])
                    new_content = content.replace(old_term, new_term)
                    self.save_chapter_content(item['id'], new_content)
                    # è¿˜éœ€è¦æ›´æ–°å‘é‡åº“å—ï¼Ÿç†è®ºä¸Šéœ€è¦ï¼Œä½†å¤ªæ…¢äº†ï¼Œå»ºè®®ç”¨æˆ·æ‰‹åŠ¨è§¦å‘æˆ–åå°æ…¢æ…¢æ›´ã€‚
                    # è¿™é‡Œä¸ºäº†é€Ÿåº¦æš‚ä¸æ›´æ–°RAGï¼Œåªæ›´æ–‡ä»¶ã€‚
                
                elif item['type'] == 'char':
                    chars[item['index']][item['field']] = chars[item['index']][item['field']].replace(old_term, new_term)
                    updated_files.add('char')
                
                elif item['type'] == 'item':
                    items[item['index']][item['field']] = items[item['index']][item['field']].replace(old_term, new_term)
                    updated_files.add('item')
                
                elif item['type'] == 'loc':
                    locs[item['index']][item['field']] = locs[item['index']][item['field']].replace(old_term, new_term)
                    updated_files.add('loc')

            except Exception as e:
                print(f"Replace error at {item}: {e}")

        # æ‰¹é‡ä¿å­˜
        if 'settings' in updated_files: self.save_settings(settings)
        if 'structure' in updated_files: self.save_structure(structure)
        if 'char' in updated_files: self.save_characters(chars)
        if 'item' in updated_files: self.save_items(items)
        if 'loc' in updated_files: self.save_locations(locs)
        
        return f"å·²åœ¨ {len(target_items)} å¤„å®Œæˆæ›¿æ¢"
    
    # 1. åˆ›å»ºå…¨é¡¹ç›®å¤‡ä»½ (ZIP)
    def create_project_backup(self, backup_dir="backups"):
        try:
            if not os.path.exists(backup_dir): os.makedirs(backup_dir)
            
            # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"novel_backup_{timestamp}"
            archive_path = os.path.join(backup_dir, filename)
            
            # æ‰“åŒ… data ç›®å½•
            if os.path.exists("data"):
                shutil.make_archive(archive_path, 'zip', "data")
                
                # æ¸…ç†æ—§å¤‡ä»½ (åªä¿ç•™æœ€è¿‘ 20 ä¸ª)
                backups = sorted(glob.glob(os.path.join(backup_dir, "*.zip")))
                if len(backups) > 20:
                    for b in backups[:-20]:
                        try: os.remove(b)
                        except: pass
                return f"å·²å¤‡ä»½: {filename}.zip"
            return "æ•°æ®ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡å¤‡ä»½"
        except Exception as e:
            return f"å¤‡ä»½å¤±è´¥: {str(e)}"

    # 2. åˆ›å»ºç« èŠ‚å¿«ç…§ (History Snapshot)
    def create_chapter_snapshot(self, chapter_id, content):
        try:
            snapshot_dir = os.path.join("data", "snapshots", str(chapter_id))
            if not os.path.exists(snapshot_dir): os.makedirs(snapshot_dir)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filepath = os.path.join(snapshot_dir, f"{timestamp}.txt")
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            
            # å•ç« åªä¿ç•™æœ€è¿‘ 50 ä¸ªå¿«ç…§ï¼Œé˜²æ­¢æ–‡ä»¶çˆ†ç‚¸
            files = sorted(glob.glob(os.path.join(snapshot_dir, "*.txt")))
            if len(files) > 50:
                for f in files[:-50]:
                    try: os.remove(f)
                    except: pass
        except Exception as e:
            print(f"Snapshot error: {e}")

    # 3. è·å–ç« èŠ‚å¿«ç…§åˆ—è¡¨
    def get_chapter_snapshots(self, chapter_id):
        snapshot_dir = os.path.join("data", "snapshots", str(chapter_id))
        if not os.path.exists(snapshot_dir): return []
        
        snapshots = []
        files = sorted(glob.glob(os.path.join(snapshot_dir, "*.txt")), reverse=True)
        for f in files:
            ts_str = os.path.basename(f).replace(".txt", "")
            try:
                dt = datetime.strptime(ts_str, "%Y%m%d_%H%M%S")
                display_time = dt.strftime("%Y-%m-%d %H:%M:%S")
            except:
                display_time = ts_str
            
            try:
                with open(f, 'r', encoding='utf-8') as file:
                    preview = file.read(100).replace("\n", " ") + "..."
            except: preview = "æ— æ³•è¯»å–å†…å®¹"
                
            snapshots.append({"filename": f, "time": display_time, "preview": preview, "raw_ts": ts_str})
        return snapshots
    # ================= ğŸ² çµæ„Ÿç”Ÿæˆ (æ–°å¢) =================

    def generate_ideas(self, type_key, context=""):
        # 1. å®šä¹‰æç¤ºè¯æ¨¡æ¿
        prompts = {
            "name_char_cn": "è¯·ç”Ÿæˆ 10 ä¸ªå¥½å¬çš„ä¸­æ–‡ç„å¹»/å¤é£äººåï¼ŒåŒ…å«ç”·å¥³ï¼Œæ ¼å¼å¦‚ï¼šå¶å‡¡ã€å§¬ç´«æœˆã€‚åªè¿”å›åå­—ï¼Œç”¨é€—å·åˆ†éš”ã€‚",
            "name_char_en": "è¯·ç”Ÿæˆ 10 ä¸ªè¥¿å¹»é£æ ¼çš„äººåï¼Œæ ¼å¼å¦‚ï¼šäºšç‘ŸÂ·æ½˜å¾·æ‹‰è´¡ã€‚åªè¿”å›åå­—ï¼Œç”¨é€—å·åˆ†éš”ã€‚",
            "name_org": "è¯·ç”Ÿæˆ 10 ä¸ªéœ¸æ°”çš„å®—æ´¾æˆ–ç»„ç»‡åç§°ï¼Œå¦‚ï¼šé­‚æ®¿ã€ç‚¸å¤©å¸®ã€‚åªè¿”å›åå­—ï¼Œç”¨é€—å·åˆ†éš”ã€‚",
            "name_skill": "è¯·ç”Ÿæˆ 10 ä¸ªç‚«é…·çš„åŠŸæ³•æˆ–æ­¦æŠ€åç§°ï¼Œå¦‚ï¼šä½›æ€’ç«è²ã€å¤§è’å›šå¤©æŒ‡ã€‚åªè¿”å›åå­—ï¼Œç”¨é€—å·åˆ†éš”ã€‚",
            "name_item": "è¯·ç”Ÿæˆ 10 ä¸ªä¼ è¯´çº§æ³•å®æˆ–ä¸¹è¯åç§°ï¼Œåªè¿”å›åå­—ï¼Œç”¨é€—å·åˆ†éš”ã€‚",
            "plot_twist": f"åŸºäºå½“å‰ä¸–ç•Œè§‚ï¼š{context[:200]}...ï¼Œè¯·æ„æ€ 3 ä¸ªæ„æƒ³ä¸åˆ°çš„å‰§æƒ…è½¬æŠ˜æˆ–çªå‘äº‹ä»¶ï¼Œç”¨äºæ‰“ç ´å½“å‰çš„å¹³æ·¡å‰§æƒ…ã€‚æ¯ä¸ªç‚¹å­ 50 å­—ä»¥å†…ã€‚",
            "gold_finger": "è¯·è„‘æ´å¤§å¼€ï¼Œç”Ÿæˆ 5 ä¸ªç‹¬ç‰¹ä¸”çˆ½ç‚¹åè¶³çš„ç½‘æ–‡â€œé‡‘æ‰‹æŒ‡â€æˆ–â€œç³»ç»Ÿâ€è®¾å®šã€‚ç®€çŸ­æè¿°ã€‚"
        }
        
        prompt = prompts.get(type_key, "è¯·éšæœºç”Ÿæˆä¸€äº›çµæ„Ÿã€‚")
        
        # 2. è°ƒç”¨ LLM (å¤ç”¨å·²æœ‰çš„ sync_call_llmï¼Œæ³¨æ„è¿™é‡Œå…¶å®åº”è¯¥ç”¨å¼‚æ­¥ï¼Œä½†ä¸ºäº†ä»£ç ç®€å•å¤ç”¨ io_bound)
        # è¿™é‡Œæˆ‘ä»¬ä¸´æ—¶æ„é€ ä¸€ä¸ª system prompt
        sys_prompt = "ä½ æ˜¯ä¸€ä¸ªç½‘æ–‡çµæ„ŸåŠ©æ‰‹ã€‚è¯·åªè¿”å›è¯·æ±‚çš„å†…å®¹ï¼Œä¸è¦åºŸè¯ã€‚"
        
        try:
            # ä½¿ç”¨å·²æœ‰çš„ client
            if not client: return "é”™è¯¯ï¼šæœªé…ç½® API Key"
            
            response = client.chat.completions.create(
                model=CFG['models'].get('writer', 'gpt-3.5-turbo'), # å€Ÿç”¨ writer æ¨¡å‹
                messages=[{"role": "system", "content": sys_prompt}, {"role": "user", "content": prompt}],
                temperature=0.9 # çµæ„Ÿéœ€è¦é«˜åˆ›é€ æ€§
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"ç”Ÿæˆå¤±è´¥: {str(e)}"

# ================= å‘é‡åº“ç®¡ç†å™¨ (RAG) =================
class MemoryManager:
    def __init__(self):
        self.root_dir = CFG.get('project_dir', 'MyNovel_Data')
        db_path = os.path.join(self.root_dir, "chroma_db")
        self.client = chromadb.PersistentClient(path=db_path)
        self.embedding_fn = embedding_functions.DefaultEmbeddingFunction()
        self.collection = self.client.get_or_create_collection(name="novel_memory", embedding_function=self.embedding_fn)

    def add_chapter_memory(self, chapter_id, content):
        self.delete_chapter_memory(chapter_id)
        chunk_size = CFG.get('chunk_size', 500)
        step = chunk_size - CFG.get('overlap', 100)
        chunks = [content[i:i+chunk_size] for i in range(0, len(content), step) if len(content[i:i+chunk_size]) > 50]
        if not chunks: return
        ids = [f"ch_{chapter_id}_{i}" for i in range(len(chunks))]
        metadatas = [{"chapter_id": chapter_id, "chunk_index": i} for i in range(len(chunks))]
        self.collection.upsert(documents=chunks, metadatas=metadatas, ids=ids)

    def delete_chapter_memory(self, chapter_id):
        try: self.collection.delete(where={"chapter_id": chapter_id})
        except Exception as e: print(f"[RAG Error] {e}")

    def query_related_memory(self, query_text, n_results=5, threshold=1.5, exclude_chapter_id=None):
        where_filter = None
        if exclude_chapter_id is not None:
            where_filter = {"chapter_id": {"$ne": exclude_chapter_id}}
        try:
            if self.collection.count() == 0: return [], []
            results = self.collection.query(query_texts=[query_text], n_results=n_results, include=['documents', 'distances', 'metadatas'], where=where_filter)
        except Exception as e: return [], []

        valid_docs = []
        debug_info = []
        if results['documents'] and results['documents'][0]:
            for doc, dist, meta in zip(results['documents'][0], results['distances'][0], results['metadatas'][0]):
                is_valid = dist < threshold
                debug_info.append({"text": doc, "distance": round(dist, 4), "source": f"ç¬¬{meta['chapter_id']}ç« ", "valid": is_valid})
                if is_valid: valid_docs.append(doc)
        return valid_docs, debug_info

# ================= LLM è°ƒç”¨æ¥å£ =================

def sync_call_llm(prompt, system_prompt, task_type="writer"):
    model_name = CFG['models'].get(task_type, "deepseek-chat")
    temperature = CFG['temperatures'].get(task_type, 1.3)
    print(f"\n[LLM Router] ä»»åŠ¡: {task_type} | æ¨¡å‹: {model_name}")
    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": prompt}],
            stream=False,
            temperature=temperature
        )
        return response.choices[0].message.content
    except Exception as e: return f"Error: {str(e)}"

def sync_rewrite_llm(selected_text, context_pre, context_post, instruction):
    task_type = "editor"
    model_name = CFG['models'].get(task_type, "deepseek-chat")
    temperature = CFG['temperatures'].get(task_type, 0.7)
    prompt = f"ã€ä»»åŠ¡ã€‘é‡å†™æ–‡æœ¬ã€‚\nã€ä¸Šæ–‡ã€‘...{context_pre[-500:]}\nã€å¾…ä¿®æ”¹ã€‘{selected_text}\nã€ä¸‹æ–‡ã€‘{context_post[:500]}...\nã€è¦æ±‚ã€‘{instruction}"
    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "system", "content": "ä¸“ä¸šç¼–è¾‘"}, {"role": "user", "content": prompt}],
            stream=False,
            temperature=temperature
        )
        return response.choices[0].message.content
    except Exception as e: return f"Error: {str(e)}"

def sync_review_chapter(content, context_str):
    task_type = "reviewer"
    model_name = CFG['models'].get(task_type, "deepseek-chat")
    temperature = CFG['temperatures'].get(task_type, 0.5)
    sys_prompt = CFG['prompts'].get('reviewer_system', "ä½ æ˜¯ä¸€ä¸ªä¸¥å‰çš„ç¼–è¾‘ã€‚")
    prompt = f"ã€å¾…å®¡æŸ¥æ­£æ–‡ã€‘\n{content}\nã€å‚è€ƒè®¾å®šã€‘\n{context_str}\nã€ä»»åŠ¡ã€‘å®¡æŸ¥é€»è¾‘ä¸€è‡´æ€§ã€å‰§æƒ…èŠ‚å¥ã€æ–‡ç¬”ã€‚è¾“å‡ºMarkdownæŠ¥å‘Šã€‚"
    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "system", "content": sys_prompt}, {"role": "user", "content": prompt}],
            stream=False,
            temperature=temperature
        )
        return response.choices[0].message.content
    except Exception as e: return f"Error: {str(e)}"

def sync_analyze_time(content, prev_time_label):
    task_type = "timekeeper"
    model_name = CFG['models'].get(task_type, "deepseek-chat")
    temperature = CFG['temperatures'].get(task_type, 0.1)
    sys_prompt = CFG['prompts'].get('timekeeper_system', "ä½ æ˜¯ä¸€ä¸ªæ—¶é—´è®°å½•å‘˜ã€‚")
    prompt = f"ã€ä¸Šä¸€ç« æ—¶é—´ã€‘{prev_time_label}\nã€æœ¬ç« æ­£æ–‡ã€‘{content[:3000]}...\nã€ä»»åŠ¡ã€‘1.åˆ†ææ—¶é—´æµé€ 2.æ¨ç®—å½“å‰æ—¶é—´ 3.æå–äº‹ä»¶\nã€è¾“å‡ºæ ¼å¼ã€‘ä¸¥æ ¼JSON: {{\"label\": \"...\", \"duration\": \"...\", \"events\": [\"...\"]}}"
    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "system", "content": sys_prompt}, {"role": "user", "content": prompt}],
            stream=False,
            temperature=temperature
        )
        return response.choices[0].message.content
    except Exception as e: return f"Error: {str(e)}"

# ã€ä¿®æ”¹ã€‘çŠ¶æ€åˆ†ææ¥å£ï¼šå¢åŠ æå–â€œåœ°ç‚¹è¿æ¥â€çš„æŒ‡ä»¤
def sync_analyze_state(content, current_data_summary):
    task_type = "auditor"
    model_name = CFG['models'].get(task_type, "deepseek-reasoner")
    temperature = CFG['temperatures'].get(task_type, 1.0)
    sys_prompt = CFG['prompts'].get('auditor_system', "ä½ æ˜¯ä¸€ä¸ªä¸–ç•Œè§‚ç®¡ç†å‘˜ã€‚")
    
    prompt = f"""
    ã€å½“å‰æ­£æ–‡ã€‘
    {content[:4000]}...
    
    ã€ç°æœ‰æ•°æ®åº“æ‘˜è¦ã€‘
    {current_data_summary}
    
    ã€ä»»åŠ¡ã€‘
    è¯·åˆ†ææ­£æ–‡ï¼Œæ£€æµ‹ä»¥ä¸‹å˜åŒ–ï¼š
    1. **äººç‰©çŠ¶æ€å˜æ›´**ï¼šç­‰çº§ã€çŠ¶æ€(å—ä¼¤/æ­»äº¡)ã€æ‰€å±åŠ¿åŠ›ã€‚
    2. **ç‰©å“å˜æ›´**ï¼šæŒæœ‰è€…è½¬ç§»ã€ç‰©å“çŠ¶æ€å˜åŒ–ã€æ–°ç‰©å“è·å¾—ã€‚
    3. **æ–°å®ä½“**ï¼šæ˜¯å¦å‡ºç°äº†**é‡è¦**çš„æ–°äººç‰©ã€æ–°ç‰©å“æˆ–æ–°åœ°ç‚¹ï¼Ÿ
    4. **äººé™…å…³ç³»å˜æ›´**ï¼šæå–æ–°å…³ç³»ï¼ˆå¦‚æ‹œå¸ˆã€ç»“ä»‡ï¼‰æˆ–å…³ç³»å˜åŒ–ã€‚
    5. **åœ°ç‚¹è¿æ¥ (æ–°)**ï¼šä¸»è§’æ˜¯å¦ä»ä¸€ä¸ªåœ°ç‚¹ç§»åŠ¨åˆ°äº†å¦ä¸€ä¸ªåœ°ç‚¹ï¼Ÿå¦‚æœæ˜¯ï¼Œè¿™æ„å‘³ç€ä¸¤ä¸ªåœ°ç‚¹æ˜¯è¿é€šçš„ã€‚æå–è¿™ç§æ‹“æ‰‘å…³ç³»ã€‚
    
    ã€è¾“å‡ºæ ¼å¼ã€‘
    ä¸¥æ ¼ JSON æ ¼å¼ï¼Œå­—æ®µå¦‚ä¸‹ï¼š
    {{
        "char_updates": [{{"name": "...", "field": "...", "new_value": "...", "reason": "..."}}],
        "item_updates": [{{"name": "...", "field": "...", "new_value": "..."}}],
        "new_chars": [{{"name": "...", "gender": "...", "role": "...", "status": "...", "bio": "..."}}],
        "new_items": [{{"name": "...", "type": "...", "owner": "...", "desc": "..."}}],
        "new_locs": [{{"name": "...", "faction": "...", "desc": "..."}}],
        "relation_updates": [
            {{"source": "ä¸»åŠ¨æ–¹", "target": "è¢«åŠ¨æ–¹", "type": "å…³ç³»ç±»å‹", "desc": "è¯´æ˜"}}
        ],
        "loc_connections": [
            {{"source": "åœ°ç‚¹A", "target": "åœ°ç‚¹B", "desc": "ç§»åŠ¨/è¿æ¥è¯´æ˜"}}
        ]
    }}
    """
    print(f"\n[LLM Router] ä»»åŠ¡: State Auditor | æ¨¡å‹: {model_name}")
    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "system", "content": sys_prompt}, {"role": "user", "content": prompt}],
            stream=False,
            temperature=temperature
        )
        return response.choices[0].message.content
    except Exception as e: return f"Error: {str(e)}"

# ã€ä¿®æ”¹ã€‘åº”ç”¨å˜æ›´ï¼šå¢åŠ å¤„ç†â€œåœ°ç‚¹è¿æ¥â€çš„é€»è¾‘
def apply_state_changes(novel_manager, changes):
    logs = []
    
    # 1. æ›´æ–°äººç‰© (ä¿æŒä¸å˜)
    chars = novel_manager.load_characters()
    for update in changes.get('char_updates', []):
        for char in chars:
            if char['name'] == update['name']:
                char[update['field']] = update['new_value']
                logs.append(f"æ›´æ–°äººç‰© [{char['name']}]: {update['field']} -> {update['new_value']}")
    
    for new_char in changes.get('new_chars', []):
        if not any(c['name'] == new_char['name'] for c in chars):
            if 'relations' not in new_char: new_char['relations'] = []
            chars.append(new_char)
            logs.append(f"æ–°å¢äººç‰©: {new_char['name']}")
            
    for rel in changes.get('relation_updates', []):
        source_char = next((c for c in chars if c['name'] == rel['source']), None)
        if source_char:
            existing_rel = next((r for r in source_char['relations'] if r['target'] == rel['target']), None)
            if existing_rel:
                existing_rel['type'] = rel['type']
                logs.append(f"æ›´æ–°å…³ç³»: {rel['source']} -> {rel['target']} ({rel['type']})")
            else:
                source_char['relations'].append({"target": rel['target'], "type": rel['type']})
                logs.append(f"æ–°å¢å…³ç³»: {rel['source']} -> {rel['target']} ({rel['type']})")
    
    novel_manager.save_characters(chars)

    # 2. æ›´æ–°ç‰©å“ (ä¿æŒä¸å˜)
    items = novel_manager.load_items()
    for update in changes.get('item_updates', []):
        for item in items:
            if item['name'] == update['name']:
                item[update['field']] = update['new_value']
                logs.append(f"æ›´æ–°ç‰©å“ [{item['name']}]: {update['field']} -> {update['new_value']}")
    for new_item in changes.get('new_items', []):
        if not any(i['name'] == new_item['name'] for i in items):
            items.append(new_item)
            logs.append(f"æ–°å¢ç‰©å“: {new_item['name']}")
    novel_manager.save_items(items)

    # 3. æ›´æ–°åœ°ç‚¹ (å¢åŠ è¿æ¥å¤„ç†é€»è¾‘)
    locs = novel_manager.load_locations()
    
    # A. å…ˆå¤„ç†æ–°åœ°ç‚¹ (é˜²æ­¢è¿æ¥æ—¶æ‰¾ä¸åˆ°åœ°ç‚¹)
    for new_loc in changes.get('new_locs', []):
        if not any(l['name'] == new_loc['name'] for l in locs):
            if 'neighbors' not in new_loc: new_loc['neighbors'] = []
            locs.append(new_loc)
            logs.append(f"æ–°å¢åœ°ç‚¹: {new_loc['name']}")
    
    # B. å¤„ç†è¿æ¥å…³ç³»
    for conn in changes.get('loc_connections', []):
        loc_a = next((l for l in locs if l['name'] == conn['source']), None)
        loc_b = next((l for l in locs if l['name'] == conn['target']), None)
        
        if loc_a and loc_b:
            # ç¡®ä¿æœ‰ neighbors å­—æ®µ
            if 'neighbors' not in loc_a: loc_a['neighbors'] = []
            if 'neighbors' not in loc_b: loc_b['neighbors'] = []
            
            # åŒå‘æ·»åŠ  (é¿å…é‡å¤)
            added = False
            if conn['target'] not in loc_a['neighbors']:
                loc_a['neighbors'].append(conn['target'])
                added = True
            if conn['source'] not in loc_b['neighbors']:
                loc_b['neighbors'].append(conn['source'])
                added = True
            
            if added:
                logs.append(f"æ–°å¢åœ°å›¾è¿æ¥: {conn['source']} â†”ï¸ {conn['target']}")

    novel_manager.save_locations(locs)

    return logs

def export_full_novel(novel_manager):
    structure = novel_manager.load_structure()
    full_text = [f"ã€ŠAI ç”Ÿæˆé•¿ç¯‡å°è¯´ã€‹\næ€»å­—æ•°ï¼š{novel_manager.get_total_word_count()}\n{'='*30}\n\n"]
    for chap in structure:
        title = f"ç¬¬{chap['id']}ç«  {chap['title']}"
        content = novel_manager.load_chapter_content(chap['id'])
        full_text.extend([title, "-" * 20, content, "\n\n"])
    return "\n".join(full_text)